{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import bgr8_to_jpeg\n",
    "from jetbot import ObjectDetector\n",
    "from jetbot import Camera\n",
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up camera and robot, load pre-trained SSD model for COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectDetector('../Notebooks/object_following/ssd_mobilenet_v2_coco.engine')\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO labels\n",
    "filename = \"coco_labels.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "COCO_labels = pickle.load(filehandler)\n",
    "\n",
    "# Load camera calibration data for undistort\n",
    "filename = \"calibration.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "camera_cal = pickle.load(filehandler)\n",
    "mtx = camera_cal['mtx']\n",
    "dist = camera_cal['dist']\n",
    "\n",
    "# Open Image Widget\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "BLUE = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bbox_TV = [(102, 90), (161, 134)]\n",
    "\n",
    "pos1_bbox_TV = [(102, 90), (164, 135)]\n",
    "pos1_bbox_stool = [(168, 123), (200, 182)]\n",
    "\n",
    "pos2_bbox_TV = [(99, 79), (170, 128)]\n",
    "pos2_bbox_stool = [(171, 115), (211, 183)]\n",
    "\n",
    "pos2left_bbox_TV = [(136, 64), (218, 132)]\n",
    "pos2left_bbox_stool = [(215, 96), (283, 187)]\n",
    "\n",
    "pos2right_bbox_TV = [(51, 69), (134, 131)]\n",
    "pos2right_bbox_stool = [(131, 122), (164, 184)]\n",
    "\n",
    "pos3_bbox_TV = [(90, 72), (172, 127)]\n",
    "pos3_bbox_stool = [(172, 107), (219, 189)]\n",
    "\n",
    "# Bbox for TV and stool at various camera poses\n",
    "beg_bbox_TV = [(72, 92), (136, 137)]  # Pose (0,0,0)\n",
    "mid_bbox_TV = [(33, 69), (114, 124)]  # Pose (0.5,0,0)\n",
    "mid_bbox_stool = [(175, 125), (216, 183)]   # Pose (0.5,0,0)\n",
    "end_bbox_stool = [(164, 101), (217, 185)]   # Pose (1.0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist, crop=False):\n",
    "    \"\"\"Undistort camera image based on calibration data\"\"\"\n",
    "    h,w = img.shape[:2]\n",
    "    # print (h,w)\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    # undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image (optional)\n",
    "    if crop:\n",
    "        x,y,w,h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def draw_bbox(img, width, height, bbox, color, line_width):\n",
    "    bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                  (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "    cv2.rectangle(img, bbox_pixel[0], bbox_pixel[1], color, line_width)\n",
    "    return bbox_pixel\n",
    "\n",
    "def display_detected(img, detections, width, height, debug=False):\n",
    "    \"\"\" put blue bounding boxes on detected objects on image \"\"\"\n",
    "    \n",
    "    for det in detections[0]:\n",
    "        label = COCO_labels[det['label']]\n",
    "        bbox = det['bbox']\n",
    "        bbox_pixel = draw_bbox(img, width, height, bbox, BLUE, 1)\n",
    "        if debug:\n",
    "            print(label,det['label'], bbox_pixel)\n",
    "    return\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections, debug= False):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if debug:\n",
    "            print(center)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "def create_feature_pts(bbox):\n",
    "    \"\"\" Return 4 feature points from a bounding box \"\"\"\n",
    "    # extract bounding x and y coordinates\n",
    "    UL_fp, LR_fp = bbox\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "   \n",
    "    # return UL(upper left), UR(upper right), LR(lower right), LL(lower left) feature points\n",
    "    return [(UL_fp_x, UL_fp_y), (LR_fp_x, UL_fp_y), (LR_fp_x, LR_fp_y), (UL_fp_x, LR_fp_y)]\n",
    "\n",
    "def generate_ref_obj_features(ref_obj, img, detections, width, height, debug=False):\n",
    "    \"\"\" Find reference object in detected objects and generate 4 feature points \"\"\"\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == ref_obj]\n",
    "\n",
    "    # get detection closest to center of field of view and draw it (if model detects multiple\n",
    "    # reference objects)\n",
    "    det = closest_detection(matching_detections)\n",
    "\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        # bound reference object in green\n",
    "        draw_bbox(img, width, height, bbox, GREEN, 1)\n",
    "        # convert to pixel units\n",
    "        bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                       (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "        return create_feature_pts(bbox_pixel) # return 4 feature points of bounding box\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def fp_error(current, goal):\n",
    "    \"\"\" Return error of a feature point \"\"\"\n",
    "    current_x, current_y = current\n",
    "    goal_x, goal_y = goal\n",
    "    # Use Corke's convention of (p*-p) --> gain is a +ve number\n",
    "    return (goal_x-current_x, goal_y-current_y)  \n",
    "\n",
    "def features_error(currentFeatures, goalFeatures):\n",
    "    \"\"\" Return feature points error vector \"\"\"\n",
    "    UL_current, UR_current, LR_current, LL_current = currentFeatures \n",
    "    UL_goal, UR_goal, LR_goal, LL_goal = goalFeatures \n",
    "    \n",
    "    # calculate error for each feature point\n",
    "    UL_error = fp_error(UL_current, UL_goal)\n",
    "    error_vector = np.asarray(UL_error)\n",
    "    UR_error = fp_error(UR_current, UR_goal)\n",
    "    error_vector = np.concatenate((error_vector, UR_error), axis=None)\n",
    "    LR_error = fp_error(LR_current, LR_goal)\n",
    "    error_vector = np.concatenate((error_vector, LR_error), axis=None)\n",
    "    LL_error = fp_error(LL_current, LL_goal)\n",
    "    error_vector = np.concatenate((error_vector, LL_error), axis=None)\n",
    "\n",
    "    # return 1x8 error vector of UL, UR, LR, LL feature points\n",
    "    return np.reshape(error_vector, (1,-1))\n",
    "\n",
    "def image_jacobian(fp, mtx, depth):\n",
    "    \"\"\" Generate image jacobiab L for a feature point \"\"\"\n",
    "    # focal lengths in pixel unit\n",
    "    f_u = mtx[0,0]\n",
    "    f_v = mtx[1,1]\n",
    "    c_u = mtx[0,2]\n",
    "    c_v = mtx[1,2]\n",
    "\n",
    "    # Estimated distance of reference object (m)\n",
    "    Z = depth\n",
    "\n",
    "    # Calculate J of feature point\n",
    "    u_raw, v_raw = fp\n",
    "    u = u_raw - c_u\n",
    "    v = v_raw - c_v    \n",
    "    \n",
    "    L = np.array([[-f_u/Z, 0, u/Z, u*v/f_u, -(f_u+u*u/f_u), v],\n",
    "                  [0, -f_v/Z, v/Z, f_v+v*v/f_v, -u*v/f_v, -u]])\n",
    "    return L\n",
    "\n",
    "def robot2world(robot_orientation):\n",
    "    \"\"\" calculate the robot jacobian \"\"\"\n",
    "    theta = robot_orientation\n",
    "    \n",
    "    return np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "\n",
    "def control2robot(wheel_radius, axle_length):\n",
    "    \"\"\" transform wheel speeds to robot motion in world frame \"\"\"\n",
    "    l = axle_length\n",
    "    r = wheel_radius\n",
    "\n",
    "    return np.array([[r/2, r/2],\n",
    "                  [r/l, -r/l]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a58607cc3c4224b99f56f942098cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 laptop [(33, 69), (114, 69), (114, 124), (33, 124)]\n",
      "laptop 72 [(81, 125), (160, 177)]\n",
      "mouse 73 [(81, 125), (160, 177)]\n",
      "[(81, 125), (160, 125), (160, 177), (81, 177)]\n",
      "[[-48 -56 -46 -56 -46 -53 -48 -53]]\n",
      "[[0.43876793]\n",
      " [0.45382236]]\n",
      "[[ 0.01450459]\n",
      " [-0.00407724]]\n",
      "laptop 72 [(79, 125), (161, 177)]\n",
      "mouse 73 [(79, 125), (161, 177)]\n",
      "laptop 72 [(79, 124), (161, 177)]\n",
      "mouse 73 [(79, 124), (161, 177)]\n",
      "[(79, 124), (161, 124), (161, 177), (79, 177)]\n",
      "[[-46 -55 -47 -55 -47 -53 -46 -53]]\n",
      "[[0.43486502]\n",
      " [0.44927327]]\n",
      "[[ 0.01436725]\n",
      " [-0.00390223]]\n",
      "laptop 72 [(82, 122), (163, 175)]\n",
      "mouse 73 [(82, 122), (163, 175)]\n",
      "laptop 72 [(82, 118), (162, 175)]\n",
      "mouse 73 [(82, 118), (162, 175)]\n",
      "[(82, 118), (162, 118), (162, 175), (82, 175)]\n",
      "[[-49 -49 -48 -49 -48 -51 -49 -51]]\n",
      "[[0.44088635]\n",
      " [0.45270298]]\n",
      "[[ 0.01452083]\n",
      " [-0.00320034]]\n",
      "laptop 72 [(80, 115), (168, 174)]\n",
      "mouse 73 [(80, 115), (163, 176)]\n",
      "66 65 [(6, 168), (342, 393)]\n",
      "laptop 72 [(69, 113), (164, 174)]\n",
      "66 65 [(5, 168), (357, 394)]\n",
      "[(69, 113), (164, 113), (164, 174), (69, 174)]\n",
      "[[-36 -44 -50 -44 -50 -50 -36 -50]]\n",
      "[[0.39927328]\n",
      " [0.40965728]]\n",
      "[[ 0.01314512]\n",
      " [-0.00281233]]\n",
      "laptop 72 [(59, 109), (157, 174)]\n",
      "bed 64 [(156, 199), (203, 242)]\n",
      "laptop 72 [(60, 109), (157, 174)]\n",
      "[(60, 109), (157, 109), (157, 174), (60, 174)]\n",
      "[[-27 -40 -43 -40 -43 -50 -27 -50]]\n",
      "[[0.34391968]\n",
      " [0.35538468]]\n",
      "[[ 0.0113637]\n",
      " [-0.0031051]]\n",
      "66 65 [(3, 169), (260, 391)]\n",
      "laptop 72 [(61, 109), (156, 174)]\n",
      "laptop 72 [(60, 109), (156, 174)]\n",
      "66 65 [(2, 174), (280, 391)]\n",
      "[(60, 109), (156, 109), (156, 174), (60, 174)]\n",
      "[[-27 -40 -42 -40 -42 -50 -27 -50]]\n",
      "[[0.34067443]\n",
      " [0.35237702]]\n",
      "[[ 0.01126209]\n",
      " [-0.00316945]]\n",
      "laptop 72 [(62, 110), (158, 175)]\n",
      "laptop 72 [(66, 109), (158, 175)]\n",
      "[(66, 109), (158, 109), (158, 175), (66, 175)]\n",
      "[[-33 -40 -44 -40 -44 -51 -33 -51]]\n",
      "[[0.36743902]\n",
      " [0.37853859]]\n",
      "[[ 0.01212214]\n",
      " [-0.00300613]]\n",
      "laptop 72 [(69, 111), (161, 175)]\n",
      "laptop 72 [(69, 111), (162, 175)]\n",
      "bed 64 [(158, 198), (210, 246)]\n",
      "[(69, 111), (162, 111), (162, 175), (69, 175)]\n",
      "[[-36 -42 -48 -42 -48 -51 -36 -51]]\n",
      "[[0.3918564 ]\n",
      " [0.40235352]]\n",
      "[[ 0.01290591]\n",
      " [-0.00284297]]\n",
      "laptop 72 [(70, 111), (162, 176)]\n",
      "bed 64 [(158, 197), (210, 246)]\n",
      "laptop 72 [(70, 110), (162, 176)]\n",
      "bed 64 [(158, 197), (210, 245)]\n",
      "[(70, 110), (162, 110), (162, 176), (70, 176)]\n",
      "[[-37 -41 -48 -41 -48 -52 -37 -52]]\n",
      "[[0.39501822]\n",
      " [0.40532117]]\n",
      "[[ 0.01300552]\n",
      " [-0.00279038]]\n",
      "laptop 72 [(70, 111), (163, 175)]\n",
      "laptop 72 [(70, 111), (163, 174)]\n",
      "[(70, 111), (163, 111), (163, 174), (70, 174)]\n",
      "[[-37 -42 -49 -42 -49 -50 -37 -50]]\n",
      "[[0.39709487]\n",
      " [0.40715368]]\n",
      "[[ 0.01306904]\n",
      " [-0.00272426]]\n",
      "laptop 72 [(73, 111), (165, 175)]\n",
      "66 65 [(16, 201), (319, 395)]\n",
      "laptop 72 [(70, 110), (164, 176)]\n",
      "[(70, 110), (164, 110), (164, 176), (70, 176)]\n",
      "[[-37 -41 -50 -41 -50 -52 -37 -52]]\n",
      "[[0.40128576]\n",
      " [0.4110877 ]]\n",
      "[[ 0.01320107]\n",
      " [-0.00265469]]\n",
      "laptop 72 [(67, 111), (160, 178)]\n",
      "laptop 72 [(56, 108), (158, 174)]\n",
      "[(56, 108), (158, 108), (158, 174), (56, 174)]\n",
      "[[-23 -39 -44 -39 -44 -50 -23 -50]]\n",
      "[[0.3332976 ]\n",
      " [0.34442664]]\n",
      "[[ 0.01101302]\n",
      " [-0.00301412]]\n",
      "laptop 72 [(55, 106), (155, 175)]\n",
      "laptop 72 [(51, 105), (151, 172)]\n",
      "[(51, 105), (151, 105), (151, 172), (51, 172)]\n",
      "[[-18 -36 -37 -36 -37 -48 -18 -48]]\n",
      "[[0.28958202]\n",
      " [0.30134574]]\n",
      "[[ 0.00960258]\n",
      " [-0.00318601]]\n",
      "laptop 72 [(44, 102), (152, 171)]\n",
      "laptop 72 [(46, 102), (153, 171)]\n",
      "[(46, 102), (153, 102), (153, 171), (46, 171)]\n",
      "[[-13 -33 -39 -33 -39 -47 -13 -47]]\n",
      "[[0.27603991]\n",
      " [0.28665818]]\n",
      "[[ 0.00914384]\n",
      " [-0.00287578]]\n",
      "laptop 72 [(47, 102), (154, 170)]\n",
      "laptop 72 [(44, 102), (150, 168)]\n",
      "[(44, 102), (150, 102), (150, 168), (44, 168)]\n",
      "[[-11 -33 -36 -33 -36 -44 -11 -44]]\n",
      "[[0.25692783]\n",
      " [0.26773495]]\n",
      "[[ 0.00852577]\n",
      " [-0.00292693]]\n",
      "laptop 72 [(44, 99), (150, 168)]\n",
      "66 65 [(5, 160), (184, 253)]\n",
      "laptop 72 [(43, 99), (148, 170)]\n",
      "66 65 [(6, 159), (184, 252)]\n",
      "[(43, 99), (148, 99), (148, 170), (43, 170)]\n",
      "[[-10 -30 -34 -30 -34 -46 -10 -46]]\n",
      "[[0.24629208]\n",
      " [0.25706579]]\n",
      "[[ 0.00817957]\n",
      " [-0.00291788]]\n",
      "laptop 72 [(45, 100), (148, 167)]\n",
      "laptop 72 [(39, 96), (148, 170)]\n",
      "66 65 [(5, 160), (185, 254)]\n",
      "couch 62 [(143, 180), (206, 256)]\n",
      "[(39, 96), (148, 96), (148, 170), (39, 170)]\n",
      "[[ -6 -27 -34 -27 -34 -46  -6 -46]]\n",
      "[[0.23041042]\n",
      " [0.24060605]]\n",
      "[[ 0.00765402]\n",
      " [-0.00276132]]\n",
      "laptop 72 [(44, 98), (151, 168)]\n",
      "laptop 72 [(37, 95), (148, 168)]\n",
      "66 65 [(7, 159), (188, 255)]\n",
      "couch 62 [(142, 178), (206, 257)]\n",
      "[(37, 95), (148, 95), (148, 168), (37, 168)]\n",
      "[[ -4 -26 -34 -26 -34 -44  -4 -44]]\n",
      "[[0.22083118]\n",
      " [0.23056544]]\n",
      "[[ 0.0073352 ]\n",
      " [-0.00263636]]\n",
      "laptop 72 [(42, 95), (149, 167)]\n",
      "66 65 [(6, 159), (188, 254)]\n",
      "laptop 72 [(42, 95), (151, 167)]\n",
      "66 65 [(7, 160), (188, 253)]\n",
      "[(42, 95), (151, 95), (151, 167), (42, 167)]\n",
      "[[ -9 -26 -37 -26 -37 -43  -9 -43]]\n",
      "[[0.24485882]\n",
      " [0.25369933]]\n",
      "[[ 0.00810157]\n",
      " [-0.00239431]]\n",
      "laptop 72 [(44, 97), (153, 169)]\n",
      "laptop 72 [(44, 97), (153, 168)]\n",
      "66 65 [(9, 163), (201, 252)]\n",
      "66 65 [(2, 171), (315, 390)]\n",
      "[(44, 97), (153, 97), (153, 168), (44, 168)]\n",
      "[[-11 -28 -39 -28 -39 -44 -11 -44]]\n",
      "[[0.2608941 ]\n",
      " [0.26992577]]\n",
      "[[ 0.00862582]\n",
      " [-0.00244608]]\n",
      "laptop 72 [(44, 96), (155, 167)]\n",
      "66 65 [(7, 159), (185, 254)]\n",
      "couch 62 [(144, 179), (211, 253)]\n",
      "laptop 72 [(47, 95), (157, 170)]\n",
      "couch 62 [(145, 177), (214, 252)]\n",
      "[(47, 95), (157, 95), (157, 170), (47, 170)]\n",
      "[[-14 -26 -43 -26 -43 -46 -14 -46]]\n",
      "[[0.28251797]\n",
      " [0.29054433]]\n",
      "[[ 0.00931226]\n",
      " [-0.0021738 ]]\n",
      "laptop 72 [(48, 95), (158, 169)]\n",
      "couch 62 [(145, 176), (214, 253)]\n",
      "laptop 72 [(44, 91), (158, 169)]\n",
      "couch 62 [(146, 176), (215, 254)]\n",
      "[(44, 91), (158, 91), (158, 169), (44, 169)]\n",
      "[[-11 -22 -44 -22 -44 -45 -11 -45]]\n",
      "[[0.2697523 ]\n",
      " [0.27675413]]\n",
      "[[ 0.00888073]\n",
      " [-0.00189633]]\n",
      "laptop 72 [(44, 90), (158, 168)]\n",
      "couch 62 [(146, 172), (216, 253)]\n",
      "66 65 [(6, 160), (189, 252)]\n",
      "laptop 72 [(47, 90), (160, 167)]\n",
      "couch 62 [(146, 171), (217, 253)]\n",
      "[(47, 90), (160, 90), (160, 167), (47, 167)]\n",
      "[[-14 -21 -46 -21 -46 -43 -14 -43]]\n",
      "[[0.28066355]\n",
      " [0.28665311]]\n",
      "[[ 0.0092189 ]\n",
      " [-0.00162217]]\n",
      "laptop 72 [(46, 88), (162, 169)]\n",
      "couch 62 [(148, 170), (220, 253)]\n",
      "laptop 72 [(45, 88), (162, 168)]\n",
      "couch 62 [(150, 170), (218, 250)]\n",
      "[(45, 88), (162, 88), (162, 168), (45, 168)]\n",
      "[[-12 -19 -48 -19 -48 -44 -12 -44]]\n",
      "[[0.27897651]\n",
      " [0.28454184]]\n",
      "[[ 0.00915717]\n",
      " [-0.00150728]]\n",
      "laptop 72 [(44, 89), (156, 167)]\n",
      "laptop 72 [(53, 86), (162, 166)]\n",
      "[(53, 86), (162, 86), (162, 166), (53, 166)]\n",
      "[[-20 -17 -48 -17 -48 -42 -20 -42]]\n",
      "[[0.29653299]\n",
      " [0.30080388]]\n",
      "[[ 0.00970672]\n",
      " [-0.0011567 ]]\n",
      "laptop 72 [(58, 84), (165, 167)]\n",
      "FPS: 3.4\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# robot pose - may need to be updated\n",
    "depth = 2.0\n",
    "robot_theta = math.pi/8 \n",
    "\n",
    "# robot parameters\n",
    "wheel_radius = 0.0325\n",
    "axle_length = 0.12\n",
    "\n",
    "# Control loop parameters\n",
    "gain = 0.016\n",
    "Rtime = 0.1  # The loop run at 8fps --> 0.125s duration\n",
    "num_iter = 50\n",
    "interval = 2\n",
    "\n",
    "no_motion = False  # Flag to disable motor (for debugging)\n",
    "debug = True\n",
    "\"\"\"\n",
    "# Use stool as reference object\n",
    "ref_obj = 62\n",
    "goal_features = create_feature_pts(end_bbox_stool)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "\"\"\"\n",
    "# Use TV as reference object \n",
    "ref_obj = 72\n",
    "goal_features = create_feature_pts(mid_bbox_TV)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Run for fixed # of iterations\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=True) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "    \n",
    "    if obj_features is None:\n",
    "        print(\"Reference object not detected!!!\")\n",
    "        break\n",
    "    # bound reference object's feature points at goal pose in red\n",
    "    cv2.rectangle(image, goal_features[0], goal_features[2], RED, 2)\n",
    "    error = features_error(obj_features,goal_features)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(obj_features)\n",
    "        print(error)\n",
    "        \n",
    "    T = control2robot(wheel_radius, axle_length) # wheel speeds to robot velocities transform\n",
    "    H = robot2world(robot_theta)  # robot velocities to world frame transform\n",
    "    \n",
    "    # Image Jacobian based on 4 fp of reference object\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "    \n",
    "    # implement w = gain * pinv(LHT).error\n",
    "    J = np.dot(L,np.dot(H,T))\n",
    "    inv_J = np.linalg.pinv(J)\n",
    "    wheel_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "    robot_velocities = np.dot(T, wheel_velocities)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(wheel_velocities)\n",
    "        print(robot_velocities)\n",
    "    \n",
    "    w_r = wheel_velocities[0,0]\n",
    "    w_l = wheel_velocities[1,0]\n",
    "    \n",
    "    if no_motion is False:\n",
    "        robot.set_motors(w_l, w_r)\n",
    "        time.sleep(Rtime)\n",
    "        robot.stop()\n",
    "  \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "\n",
    "image_widget.value = bgr8_to_jpeg(image)\n",
    "robot.stop()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print (\"FPS: {:.1f}\".format(num_iter/(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
