{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import bgr8_to_jpeg\n",
    "from jetbot import ObjectDetector\n",
    "from jetbot import Camera\n",
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up camera and robot, load pre-trained SSD model for COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectDetector('../Notebooks/object_following/ssd_mobilenet_v2_coco.engine')\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created becasue they already exist\n"
     ]
    }
   ],
   "source": [
    "# Load COCO labels\n",
    "filename = \"coco_labels.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "COCO_labels = pickle.load(filehandler)\n",
    "\n",
    "# Load camera calibration data for undistort\n",
    "filename = \"calibration.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "camera_cal = pickle.load(filehandler)\n",
    "mtx = camera_cal['mtx']\n",
    "dist = camera_cal['dist']\n",
    "f_u = mtx[0,0]   # focal center coordinates\n",
    "f_v = mtx[1,1]\n",
    "focal_center = np.array([f_u, f_v])\n",
    "\n",
    "# Mapping between set_motor \"speed\" and measured wheel angular velocity \"omega\"\n",
    "# for 0.1 second motor running time\n",
    "wheel_calibration = {\n",
    "    \"speed\": [0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    \"omega\": [0.0, 3.85, 9.23, 15.0, 25.8, 29.2, 35.4]\n",
    "}\n",
    "\n",
    "# Open Image Widget\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "BLUE = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "\n",
    "diag_dir = 'diagnostics'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(diag_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bbox_TV = [(102, 90), (161, 134)]\n",
    "\n",
    "pos1_bbox_TV = [(102, 90), (164, 135)]\n",
    "pos1_bbox_stool = [(168, 123), (200, 182)]\n",
    "\n",
    "pos2_bbox_TV = [(99, 79), (170, 128)]\n",
    "pos2_bbox_stool = [(171, 115), (211, 183)]\n",
    "\n",
    "pos2left_bbox_TV = [(136, 64), (218, 132)]\n",
    "pos2left_bbox_stool = [(215, 96), (283, 187)]\n",
    "\n",
    "pos2right_bbox_TV = [(51, 69), (134, 131)]\n",
    "pos2right_bbox_stool = [(131, 122), (164, 184)]\n",
    "\n",
    "pos3_bbox_TV = [(90, 72), (172, 127)]\n",
    "pos3_bbox_stool = [(172, 107), (219, 189)]\n",
    "\n",
    "# Bbox for TV and stool at various camera poses\n",
    "# For (0,0,0) to (1,0,0)\n",
    "beg_bbox_TV = [(72, 92), (136, 137)]  # Pose (0,0,0)\n",
    "mid_bbox_TV = [(33, 69), (114, 124)]  # Pose (0.5,0,0)\n",
    "end_bbox_stool = [(175, 84), (237, 186)]   # Pose (1.0,0,0)\n",
    "\n",
    "# Bbox for 2nd stool at various camera poses\n",
    "# For (1,0,0) to (2,0,pi)\n",
    "end_bbox_horse = [(147, 103), (247, 201)]\n",
    "mid_bbox_stool_2 = [(163, 80), (263, 185)]   # midpoint to Pose (1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist, crop=False):\n",
    "    \"\"\"Undistort camera image based on calibration data\"\"\"\n",
    "    h,w = img.shape[:2]\n",
    "    # print (h,w)\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    # undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image (optional)\n",
    "    if crop:\n",
    "        x,y,w,h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def draw_bbox(img, width, height, bbox, color, line_width):\n",
    "    bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                  (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "    cv2.rectangle(img, bbox_pixel[0], bbox_pixel[1], color, line_width)\n",
    "    return bbox_pixel\n",
    "\n",
    "def display_detected(img, detections, width, height, debug=False):\n",
    "    \"\"\" put blue bounding boxes on detected objects on image \"\"\"\n",
    "    \n",
    "    for det in detections[0]:\n",
    "        label = COCO_labels[det['label']]\n",
    "        bbox = det['bbox']\n",
    "        bbox_pixel = draw_bbox(img, width, height, bbox, BLUE, 1)\n",
    "        if debug:\n",
    "            print(label,det['label'], bbox_pixel)\n",
    "    return\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def object_center(object_features):\n",
    "    \"\"\"Computes the center x, y coordinates of the object using its feature points\"\"\"\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "    center_x = (UL_fp_x + LR_fp_x) / 2.0 - 0.5\n",
    "    center_y = (UL_fp_y + LR_fp_y) / 2.0 - 0.5\n",
    "    return np.array([center_x, center_y])\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections, debug= False):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if debug:\n",
    "            print(center)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "def create_feature_pts(bbox):\n",
    "    \"\"\" Return 4 feature points from a bounding box \"\"\"\n",
    "    # extract bounding x and y coordinates\n",
    "    UL_fp, LR_fp = bbox\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "   \n",
    "    # return UL(upper left), UR(upper right), LR(lower right), LL(lower left) feature points\n",
    "    return [(UL_fp_x, UL_fp_y), (LR_fp_x, UL_fp_y), (LR_fp_x, LR_fp_y), (UL_fp_x, LR_fp_y)]\n",
    "\n",
    "def generate_ref_obj_features(ref_obj, img, detections, width, height, debug=False):\n",
    "    \"\"\" Find reference object in detected objects and generate 4 feature points \"\"\"\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == ref_obj]\n",
    "\n",
    "    # get detection closest to center of field of view and draw it (if model detects multiple\n",
    "    # reference objects)\n",
    "    det = closest_detection(matching_detections)\n",
    "\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        # bound reference object in green\n",
    "        draw_bbox(img, width, height, bbox, GREEN, 1)\n",
    "        # convert to pixel units\n",
    "        bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                       (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "        return create_feature_pts(bbox_pixel) # return 4 feature points of bounding box\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def fp_error(current, goal):\n",
    "    \"\"\" Return error of a feature point \"\"\"\n",
    "    current_x, current_y = current\n",
    "    goal_x, goal_y = goal\n",
    "    # Use Corke's convention of (p*-p) --> gain is a +ve number\n",
    "    return (goal_x-current_x, goal_y-current_y)  \n",
    "\n",
    "def features_error(currentFeatures, goalFeatures):\n",
    "    \"\"\" Return feature points error vector \"\"\"\n",
    "    UL_current, UR_current, LR_current, LL_current = currentFeatures \n",
    "    UL_goal, UR_goal, LR_goal, LL_goal = goalFeatures \n",
    "    \n",
    "    # calculate error for each feature point\n",
    "    UL_error = fp_error(UL_current, UL_goal)\n",
    "    error_vector = np.asarray(UL_error)\n",
    "    UR_error = fp_error(UR_current, UR_goal)\n",
    "    error_vector = np.concatenate((error_vector, UR_error), axis=None)\n",
    "    LR_error = fp_error(LR_current, LR_goal)\n",
    "    error_vector = np.concatenate((error_vector, LR_error), axis=None)\n",
    "    LL_error = fp_error(LL_current, LL_goal)\n",
    "    error_vector = np.concatenate((error_vector, LL_error), axis=None)\n",
    "\n",
    "    # return 1x8 error vector of UL, UR, LR, LL feature points\n",
    "    return np.reshape(error_vector, (1,-1))\n",
    "\n",
    "def image_jacobian(fp, mtx, depth):\n",
    "    \"\"\" Generate image jacobiab L for a feature point \"\"\"\n",
    "    # focal lengths in pixel unit\n",
    "    f_u = mtx[0,0]\n",
    "    f_v = mtx[1,1]\n",
    "    c_u = mtx[0,2]\n",
    "    c_v = mtx[1,2]\n",
    "\n",
    "    # Estimated distance of reference object (m)\n",
    "    Z = depth\n",
    "\n",
    "    # Calculate J of feature point\n",
    "    u_raw, v_raw = fp\n",
    "    u = u_raw - c_u\n",
    "    v = v_raw - c_v    \n",
    "    \n",
    "    L = np.array([[-f_u/Z, 0, u/Z, u*v/f_u, -(f_u+u*u/f_u), v],\n",
    "                  [0, -f_v/Z, v/Z, f_v+v*v/f_v, -u*v/f_v, -u]])\n",
    "    return L\n",
    "\n",
    "def robot2world(robot_orientation):\n",
    "    \"\"\" calculate the robot jacobian \"\"\"\n",
    "    theta = robot_orientation\n",
    "    \n",
    "    return np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "\n",
    "def control2robot(wheel_radius, axle_length):\n",
    "    \"\"\" transform wheel speeds to robot motion in world frame \"\"\"\n",
    "    l = axle_length\n",
    "    r = wheel_radius\n",
    "\n",
    "    return np.array([[r/2, r/2],\n",
    "                  [r/l, -r/l]])\n",
    "\n",
    "def save_snapshot(img, directory, i):\n",
    "    image_path = os.path.join(directory, 'detect'+str(i+1)+'.jpg')\n",
    "    cv2.imwrite(image_path, img) \n",
    "    return\n",
    "\n",
    "def omega2speed(in_val, mapping):\n",
    "    \"\"\" Map wheel angular speed to motor speed setting based on a calibration mapping \"\"\"\n",
    "    \n",
    "    if in_val < 0:\n",
    "        sign = -1\n",
    "        in_val = abs(in_val)\n",
    "    else:\n",
    "        sign = 1\n",
    "        \n",
    "    out_lower = 0\n",
    "    in_lower = 0\n",
    "    out_val = 0\n",
    "\n",
    "    for i, in_upper in enumerate(mapping[\"omega\"]):\n",
    "        # print (i, in_upper)\n",
    "        if in_val < in_upper:\n",
    "            out_upper = mapping[\"speed\"][i]\n",
    "            out_val = out_lower + (in_val - in_lower)/(in_upper - in_lower) \\\n",
    "                *(out_upper-out_lower)\n",
    "            # print(\"yes\", out_val)\n",
    "            break\n",
    "        else:\n",
    "            # print(\"no\")\n",
    "            out_lower = mapping[\"speed\"][i]\n",
    "            in_lower = in_upper\n",
    "            \n",
    "    if out_val is 0:\n",
    "        print (\"Input is too high!!!\", in_val)\n",
    "        out_val = 0\n",
    "        \n",
    "    return sign*out_val\n",
    "\n",
    "def rotate_left_2wheels(speed, Rtime):\n",
    "    \n",
    "    robot.set_motors(-speed, speed)\n",
    "    time.sleep(Rtime)\n",
    "    robot.stop()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e59428e2b44c159b140a9fb1f6891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 laptop [(33, 69), (114, 69), (114, 124), (33, 124)]\n",
      "couch 62 [(88, 112), (128, 182)]\n",
      "clock 84 [(138, 64), (266, 186)]\n",
      "Reference object not detected!!!\n",
      "couch 62 [(88, 112), (127, 181)]\n",
      "clock 84 [(138, 62), (266, 183)]\n",
      "clock 84 [(162, 128), (169, 148)]\n",
      "Reference object not detected!!!\n",
      "couch 62 [(88, 111), (127, 181)]\n",
      "clock 84 [(140, 68), (263, 186)]\n",
      "clock 84 [(162, 128), (169, 148)]\n",
      "Reference object not detected!!!\n",
      "couch 62 [(88, 110), (127, 181)]\n",
      "clock 84 [(137, 63), (266, 188)]\n",
      "clock 84 [(161, 128), (169, 147)]\n",
      "Reference object not detected!!!\n",
      "couch 62 [(88, 116), (126, 181)]\n",
      "clock 84 [(139, 68), (262, 185)]\n",
      "clock 84 [(161, 128), (169, 148)]\n",
      "Reference object not detected!!!\n",
      "FPS: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# robot pose - may need to be updated\n",
    "depth = 2.0\n",
    "orientation = 0 \n",
    "\n",
    "# robot parameters\n",
    "wheel_radius = 0.0325\n",
    "axle_length = 0.12\n",
    "\n",
    "# Control loop parameters\n",
    "gain = 1.35\n",
    "Rtime = 0.1  # The loop run at 8fps --> 0.125s duration\n",
    "num_iter = 5\n",
    "interval = 2\n",
    "\n",
    "no_motion = False  # Flag to disable motor (for debugging)\n",
    "debug = True\n",
    "\n",
    "# Use TV as reference object \n",
    "ref_obj = 72\n",
    "goal_features = create_feature_pts(mid_bbox_TV)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Run for fixed # of iterations\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=True) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "    \n",
    "    if obj_features is None:\n",
    "        print(\"Reference object not detected!!!\")\n",
    "        continue\n",
    "        \n",
    "    # bound reference object's feature points at goal pose in red\n",
    "    cv2.rectangle(image, goal_features[0], goal_features[2], RED, 2)\n",
    "    error = features_error(obj_features,goal_features)\n",
    "    error_norm = np.linalg.norm(error)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(obj_features)\n",
    "        print(error, error_norm)\n",
    "\n",
    "    if np.linalg.norm(error) < 10:\n",
    "        print (\"Goal point achieved!!!\")\n",
    "        break\n",
    "        \n",
    "    T = control2robot(wheel_radius, axle_length) # wheel speeds to robot velocities transform\n",
    "    H = robot2world(orientation)  # robot velocities to world frame transform\n",
    "    \n",
    "    # Image Jacobian based on 4 fp of reference object\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "    \n",
    "    # implement w = gain * pinv(LHT).error\n",
    "    J = np.dot(L,np.dot(H,T))\n",
    "    inv_J = np.linalg.pinv(J)\n",
    "    wheel_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "    robot_velocities = np.dot(T, wheel_velocities)\n",
    "    w_r = omega2speed(wheel_velocities[0,0],wheel_calibration) \n",
    "    w_l = omega2speed(wheel_velocities[1,0],wheel_calibration) \n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(\"Iteration \", i)\n",
    "        save_snapshot(image, diag_dir, i)\n",
    "        print(wheel_velocities, (w_l, w_r))\n",
    "        print(robot_velocities)\n",
    "        print(\"Orientation:\", orientation)\n",
    "        print(\"Depth:\", depth)\n",
    "    \n",
    "    if no_motion is False:\n",
    "        robot.set_motors(w_l, w_r)\n",
    "        time.sleep(Rtime)\n",
    "        robot.stop()\n",
    "    \n",
    "    # Update robot's orientation\n",
    "    translation_velocity = robot_velocities[0,0]\n",
    "    angular_velocity = robot_velocities[1,0]\n",
    "    orientation += Rtime*angular_velocity\n",
    "    depth -= Rtime*translation_velocity*math.cos(orientation)\n",
    "    \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "\n",
    "image_widget.value = bgr8_to_jpeg(image)\n",
    "robot.stop()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print (\"FPS: {:.1f}\".format(num_iter/(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c10d12511ed42c4b5d0e23bd79d1b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 couch [(175, 84), (237, 84), (237, 186), (175, 186)]\n",
      "laptop 72 [(36, 67), (119, 125)]\n",
      "couch 62 [(165, 119), (200, 184)]\n",
      "[(165, 119), (200, 119), (200, 184), (165, 184)]\n",
      "[[ 10 -35  37 -35  37   2  10   2]] 73.45747068882783\n",
      "Iteration  0\n",
      "[[-10.79290285]\n",
      " [-12.02663899]] (-0.4484686133429327, -0.4270867045439424)\n",
      "[[-0.37081755]\n",
      " [ 0.33413687]]\n",
      "Orientation: 0\n",
      "Depth: 1.3\n",
      "laptop 72 [(37, 67), (123, 126)]\n",
      "couch 62 [(164, 119), (207, 183)]\n",
      "couch 62 [(177, 119), (216, 185)]\n",
      "laptop 72 [(58, 73), (129, 131)]\n",
      "[(177, 119), (216, 119), (216, 185), (177, 185)]\n",
      "[[ -2 -35  21 -35  21   1  -2   1]] 57.810033731178535\n",
      "Iteration  2\n",
      "[[-4.88084825]\n",
      " [-6.13933353]] (-0.3425526679009986, -0.3191607481166443)\n",
      "[[-0.17907795]\n",
      " [ 0.34083976]]\n",
      "Orientation: 0.06617213520205803\n",
      "Depth: 1.3704190123356164\n",
      "laptop 72 [(73, 78), (138, 133)]\n",
      "couch 62 [(182, 122), (227, 185)]\n",
      "couch 62 [(191, 119), (236, 184)]\n",
      "laptop 72 [(86, 78), (144, 136)]\n",
      "couch 62 [(0, 104), (54, 186)]\n",
      "[(191, 119), (236, 119), (236, 184), (191, 184)]\n",
      "[[-16 -35   1 -35   1   2 -16   2]] 54.516052681756044\n",
      "Iteration  4\n",
      "[[3.01538228]\n",
      " [2.06074308]] (0.2767628971299538, 0.28916080876628647)\n",
      "[[0.08248704]\n",
      " [0.25854812]]\n",
      "Orientation: 0.1343171331233493\n",
      "Depth: 1.3937789746497955\n",
      "couch 62 [(192, 119), (240, 185)]\n",
      "laptop 72 [(87, 79), (146, 135)]\n",
      "couch 62 [(0, 108), (54, 187)]\n",
      "bird 15 [(0, 108), (54, 187)]\n",
      "couch 62 [(5, 110), (64, 188)]\n",
      "couch 62 [(199, 114), (250, 186)]\n",
      "laptop 72 [(94, 77), (155, 137)]\n",
      "bird 15 [(5, 110), (64, 188)]\n",
      "clock 84 [(104, 143), (108, 155)]\n",
      "[(199, 114), (250, 114), (250, 186), (199, 186)]\n",
      "[[-24 -30 -13 -30 -13   0 -24   0]] 57.358521598799946\n",
      "Iteration  6\n",
      "[[8.18642798]\n",
      " [7.6060203 ]] (0.3698145037162648, 0.3806027505907398)\n",
      "[[0.25662728]\n",
      " [0.15719375]]\n",
      "Orientation: 0.1846593982678267\n",
      "Depth: 1.3733867639546848\n",
      "couch 62 [(9, 111), (65, 188)]\n",
      "couch 62 [(204, 112), (260, 188)]\n",
      "laptop 72 [(96, 77), (158, 137)]\n",
      "bird 15 [(9, 111), (65, 188)]\n",
      "couch 62 [(10, 110), (66, 187)]\n",
      "couch 62 [(210, 107), (272, 188)]\n",
      "laptop 72 [(97, 74), (158, 134)]\n",
      "bird 15 [(10, 110), (66, 187)]\n",
      "[(210, 107), (272, 107), (272, 188), (210, 188)]\n",
      "[[-35 -23 -35 -23 -35  -2 -35  -2]] 77.23988606931007\n",
      "Iteration  8\n",
      "[[15.22248548]\n",
      " [15.0932054 ]] (0.5008630129776958, 0.5020600507043869)\n",
      "[[0.49262998]\n",
      " [0.03501335]]\n",
      "Orientation: 0.2116148987292986\n",
      "Depth: 1.312326997047427\n",
      "laptop 72 [(97, 71), (161, 134)]\n",
      "couch 62 [(8, 111), (67, 185)]\n",
      "couch 62 [(211, 102), (279, 188)]\n",
      "laptop 72 [(94, 62), (164, 137)]\n",
      "couch 62 [(0, 107), (63, 190)]\n",
      "couch 62 [(218, 99), (283, 187)]\n",
      "[(218, 99), (283, 99), (283, 187), (218, 187)]\n",
      "[[-43 -15 -46 -15 -46  -1 -43  -1]] 91.55326318597278\n",
      "Iteration  10\n",
      "[[18.06255402]\n",
      " [18.25525824]] (0.5301412799539781, 0.5283569816399475)\n",
      "[[ 0.59016445]\n",
      " [-0.05219073]]\n",
      "Orientation: 0.21391324598372838\n",
      "Depth: 1.2119524674030353\n",
      "laptop 72 [(85, 59), (158, 130)]\n",
      "Reference object not detected!!!\n",
      "laptop 72 [(69, 58), (146, 124)]\n",
      "couch 62 [(197, 101), (264, 189)]\n",
      "[(197, 101), (264, 101), (264, 189), (197, 189)]\n",
      "[[-22 -17 -27 -17 -27  -3 -22  -3]] 54.97272050753901\n",
      "Iteration  12\n",
      "[[9.35586022]\n",
      " [9.20280349]] (0.3994944887359714, 0.4021812863544871)\n",
      "[[0.30157829]\n",
      " [0.04145286]]\n",
      "Orientation: 0.2086941734151891\n",
      "Depth: 1.1542165440074885\n",
      "laptop 72 [(61, 53), (146, 122)]\n",
      "couch 62 [(200, 101), (257, 188)]\n",
      "laptop 72 [(51, 48), (137, 121)]\n",
      "couch 62 [(191, 99), (252, 187)]\n",
      "clock 84 [(118, 147), (127, 183)]\n",
      "[(191, 99), (252, 99), (252, 187), (191, 187)]\n",
      "[[-16 -15 -15 -15 -15  -1 -16  -1]] 37.603191353926334\n",
      "Iteration  14\n",
      "[[5.61909384]\n",
      " [5.44352632]] (0.32961944823950606, 0.3328827852008491)\n",
      "[[0.17976758]\n",
      " [0.04754954]]\n",
      "Orientation: 0.21709945161961297\n",
      "Depth: 1.0984435979913743\n",
      "laptop 72 [(44, 42), (134, 118)]\n",
      "couch 62 [(190, 98), (253, 188)]\n",
      "clock 84 [(114, 147), (127, 182)]\n",
      "laptop 72 [(32, 39), (129, 114)]\n",
      "couch 62 [(189, 96), (251, 190)]\n",
      "clock 84 [(111, 145), (122, 182)]\n",
      "[(189, 96), (251, 96), (251, 190), (189, 190)]\n",
      "[[-14 -12 -14 -12 -14  -4 -14  -4]] 33.2264954516723\n",
      "Iteration  16\n",
      "[[4.94809438]\n",
      " [4.76814044]] (0.31706580739318047, 0.3204106762282792)\n",
      "[[0.15788882]\n",
      " [0.04873753]]\n",
      "Orientation: 0.22637264771585416\n",
      "Depth: 1.0635958100226803\n",
      "laptop 72 [(20, 36), (125, 111)]\n",
      "couch 62 [(187, 94), (247, 195)]\n",
      "clock 84 [(112, 145), (121, 181)]\n",
      "clock 84 [(104, 145), (112, 183)]\n",
      "couch 62 [(187, 94), (249, 193)]\n",
      "clock 84 [(111, 142), (122, 181)]\n",
      "laptop 72 [(8, 29), (124, 107)]\n",
      "clock 84 [(103, 144), (112, 182)]\n",
      "[(187, 94), (249, 94), (249, 193), (187, 193)]\n",
      "[[-12 -10 -12 -10 -12  -7 -12  -7]] 29.563490998188964\n",
      "Iteration  18\n",
      "[[4.18260797]\n",
      " [3.96890355]] (0.30221010308914703, 0.3061823041971836)\n",
      "[[0.13246206]\n",
      " [0.05787828]]\n",
      "Orientation: 0.23876239038567995\n",
      "Depth: 1.0363785831738672\n",
      "couch 62 [(188, 95), (256, 186)]\n",
      "clock 84 [(102, 143), (111, 183)]\n",
      "clock 84 [(111, 142), (121, 182)]\n",
      "couch 62 [(179, 101), (222, 184)]\n",
      "couch 62 [(188, 91), (257, 187)]\n",
      "clock 84 [(112, 142), (122, 180)]\n",
      "clock 84 [(102, 143), (110, 181)]\n",
      "[(188, 91), (257, 91), (257, 187), (188, 187)]\n",
      "[[-13  -7 -20  -7 -20  -1 -13  -1]] 35.185224171518364\n",
      "Iteration  20\n",
      "[[5.7248141 ]\n",
      " [5.79752587]] (0.33619936559054037, 0.33484784565757103)\n",
      "[[ 0.18723802]\n",
      " [-0.01969277]]\n",
      "Orientation: 0.25862982121381994\n",
      "Depth: 1.0303331152451451\n",
      "couch 62 [(190, 91), (259, 187)]\n",
      "laptop 72 [(7, 21), (126, 108)]\n",
      "clock 84 [(112, 144), (121, 181)]\n",
      "clock 84 [(104, 145), (113, 181)]\n",
      "couch 62 [(177, 110), (214, 182)]\n",
      "couch 62 [(185, 87), (263, 184)]\n",
      "laptop 72 [(5, 16), (125, 106)]\n",
      "clock 84 [(113, 143), (122, 180)]\n",
      "[(185, 87), (263, 87), (263, 184), (185, 184)]\n",
      "[[-10  -3 -26  -3 -26   2 -10   2]] 39.72404813208241\n",
      "Iteration  22\n",
      "[[6.25823835]\n",
      " [6.51812982]] (0.3495934911181871, 0.3447627946677908)\n",
      "[[ 0.20761598]\n",
      " [-0.07038727]]\n",
      "Orientation: 0.28214888074185407\n",
      "Depth: 1.0246807129147215\n",
      "laptop 72 [(33, 28), (131, 112)]\n",
      "couch 62 [(186, 86), (264, 185)]\n",
      "clock 84 [(113, 144), (124, 181)]\n",
      "couch 62 [(191, 86), (265, 186)]\n",
      "clock 84 [(111, 142), (122, 181)]\n",
      "laptop 72 [(4, 15), (128, 106)]\n",
      "clock 84 [(102, 145), (111, 181)]\n",
      "couch 62 [(176, 113), (214, 182)]\n",
      "[(176, 113), (214, 113), (214, 182), (176, 182)]\n",
      "[[ -1 -29  23 -29  23   4  -1   4]] 52.66877632905477\n",
      "Iteration  24\n",
      "[[-3.48169917]\n",
      " [-4.5669002 ]] (-0.31332528256708747, -0.2952168723898869)\n",
      "[[-0.13078974]\n",
      " [ 0.29390861]]\n",
      "Orientation: 0.2679239170068792\n",
      "Depth: 0.984010500868152\n",
      "couch 62 [(189, 83), (267, 187)]\n",
      "clock 84 [(103, 143), (112, 182)]\n",
      "clock 84 [(112, 140), (121, 181)]\n",
      "couch 62 [(190, 85), (264, 185)]\n",
      "clock 84 [(101, 144), (111, 182)]\n",
      "clock 84 [(112, 142), (122, 180)]\n",
      "[(190, 85), (264, 85), (264, 185), (190, 185)]\n",
      "[[-15  -1 -27  -1 -27   1 -15   1]] 43.726422218150894\n",
      "Iteration  26\n",
      "[[6.95546053]\n",
      " [7.28968854]] (0.3639347313020902, 0.35772231459747744)\n",
      "[[ 0.23148367]\n",
      " [-0.09052009]]\n",
      "Orientation: 0.28797945090110855\n",
      "Depth: 0.9728164636293913\n",
      "couch 62 [(188, 87), (254, 187)]\n",
      "clock 84 [(98, 143), (109, 183)]\n",
      "couch 62 [(185, 79), (256, 186)]\n",
      "clock 84 [(96, 140), (109, 182)]\n",
      "[(185, 79), (256, 79), (256, 186), (185, 186)]\n",
      "[[-10   5 -19   5 -19   0 -10   0]] 31.176914536239792\n",
      "Iteration  28\n",
      "[[4.59203492]\n",
      " [4.90431428]] (0.3195969196172004, 0.3137924705698986)\n",
      "[[ 0.15431567]\n",
      " [-0.08457566]]\n",
      "Orientation: 0.2747610604251007\n",
      "Depth: 0.9352404654438911\n",
      "couch 62 [(184, 80), (255, 187)]\n",
      "clock 84 [(83, 140), (94, 182)]\n",
      "FPS: 3.4\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# robot pose - may need to be updated\n",
    "depth = 1.3\n",
    "orientation = 0 \n",
    "\n",
    "# Control loop parameters\n",
    "gain = 1.5\n",
    "Rtime = 0.1  # The loop run at 8fps --> 0.125s duration\n",
    "num_iter = 30\n",
    "interval = 2\n",
    "\n",
    "no_motion = False  # Flag to disable motor (for debugging)\n",
    "debug = True\n",
    "\n",
    "# Use stool as reference object\n",
    "ref_obj = 62\n",
    "goal_features = create_feature_pts(end_bbox_stool)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Run for fixed # of iterations\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=True) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "    \n",
    "    if obj_features is None:\n",
    "        print(\"Reference object not detected!!!\")\n",
    "        continue\n",
    "        \n",
    "    # bound reference object's feature points at goal pose in red\n",
    "    cv2.rectangle(image, goal_features[0], goal_features[2], RED, 2)\n",
    "    error = features_error(obj_features,goal_features)\n",
    "    error_norm = np.linalg.norm(error)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(obj_features)\n",
    "        print(error, error_norm)\n",
    "\n",
    "    if np.linalg.norm(error) < 10:\n",
    "        print (\"Goal point achieved!!!\")\n",
    "        break\n",
    "        \n",
    "    T = control2robot(wheel_radius, axle_length) # wheel speeds to robot velocities transform\n",
    "    H = robot2world(orientation)  # robot velocities to world frame transform\n",
    "    \n",
    "    # Image Jacobian based on 4 fp of reference object\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "    \n",
    "    # implement w = gain * pinv(LHT).error\n",
    "    J = np.dot(L,np.dot(H,T))\n",
    "    inv_J = np.linalg.pinv(J)\n",
    "    wheel_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "    robot_velocities = np.dot(T, wheel_velocities)\n",
    "    w_r = omega2speed(wheel_velocities[0,0],wheel_calibration) \n",
    "    w_l = omega2speed(wheel_velocities[1,0],wheel_calibration) \n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(\"Iteration \", i)\n",
    "        save_snapshot(image, diag_dir, i)\n",
    "        print(wheel_velocities, (w_l, w_r))\n",
    "        print(robot_velocities)\n",
    "        print(\"Orientation:\", orientation)\n",
    "        print(\"Depth:\", depth)\n",
    "    \n",
    "    if no_motion is False:\n",
    "        robot.set_motors(w_l, w_r)\n",
    "        time.sleep(Rtime)\n",
    "        robot.stop()\n",
    "    \n",
    "    # Update robot's orientation\n",
    "    translation_velocity = robot_velocities[0,0]\n",
    "    angular_velocity = robot_velocities[1,0]\n",
    "    orientation += Rtime*angular_velocity\n",
    "    depth -= Rtime*translation_velocity*math.cos(orientation)\n",
    "    \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "\n",
    "image_widget.value = bgr8_to_jpeg(image)\n",
    "robot.stop()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print (\"FPS: {:.1f}\".format(num_iter/(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 horse\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee04749e7a4a441a8503aacf430eedf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse  at  [(0, 93), (81, 93), (81, 204), (0, 204)]\n",
      "norm(distance): 107.94763831886796\n",
      "horse  at  [(0, 95), (101, 95), (101, 200), (0, 200)]\n",
      "norm(distance): 98.92121002957626\n",
      "horse  at  [(0, 95), (107, 95), (107, 201), (0, 201)]\n",
      "norm(distance): 95.95022037025906\n",
      "horse  at  [(20, 100), (120, 100), (120, 198), (20, 198)]\n",
      "norm(distance): 80.44948792548179\n",
      "horse  at  [(26, 103), (127, 103), (127, 203), (26, 203)]\n",
      "norm(distance): 72.86130562851815\n",
      "horse  at  [(69, 110), (154, 110), (154, 197), (69, 197)]\n",
      "norm(distance): 43.426848665426306\n",
      "Reference object near focal center !!!\n"
     ]
    }
   ],
   "source": [
    "# Use horse as reference object\n",
    "ref_obj = 18\n",
    "print(ref_obj,COCO_labels[ref_obj])\n",
    "Rtime = 0.05\n",
    "speed = 0.3\n",
    "\n",
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "for i in range(100):\n",
    "    rotate_left_2wheels(speed, Rtime)\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=False) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "\n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "    \n",
    "    if obj_features is None:\n",
    "        continue\n",
    "    else:\n",
    "        Rtime = 0.01\n",
    "        speed = 0.29\n",
    "        norm_distance = np.linalg.norm(focal_center - object_center(obj_features))\n",
    "        print(COCO_labels[ref_obj], \" at \", obj_features)\n",
    "        print(\"norm(distance):\", norm_distance)\n",
    "        if  norm_distance < 70:\n",
    "            print(\"Reference object near focal center !!!\")\n",
    "            break\n",
    "        continue\n",
    " \n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 couch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25c0fb51bfb497a969e3b5fe0470240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couch  at  [(226, 68), (297, 68), (297, 197), (226, 197)]\n",
      "norm(distance): 129.68433209141097\n",
      "couch  at  [(12, 109), (68, 109), (68, 186), (12, 186)]\n",
      "norm(distance): 108.75113087281461\n",
      "couch  at  [(15, 109), (71, 109), (71, 185), (15, 185)]\n",
      "norm(distance): 106.10256197627851\n",
      "couch  at  [(22, 111), (78, 111), (78, 185), (22, 185)]\n",
      "norm(distance): 99.20389279946687\n",
      "couch  at  [(23, 113), (78, 113), (78, 184), (23, 184)]\n",
      "norm(distance): 98.55708801140236\n",
      "couch  at  [(26, 114), (82, 114), (82, 183), (26, 183)]\n",
      "norm(distance): 95.29969590623294\n",
      "couch  at  [(28, 110), (82, 110), (82, 184), (28, 184)]\n",
      "norm(distance): 94.94589002336771\n",
      "couch  at  [(28, 110), (82, 110), (82, 184), (28, 184)]\n",
      "norm(distance): 94.94589002336771\n",
      "couch  at  [(29, 108), (83, 108), (83, 186), (29, 186)]\n",
      "norm(distance): 94.02554296677076\n",
      "couch  at  [(34, 111), (85, 111), (85, 185), (34, 185)]\n",
      "norm(distance): 90.41531383731953\n",
      "couch  at  [(38, 113), (87, 113), (87, 183), (38, 183)]\n",
      "norm(distance): 87.67081082036847\n",
      "couch  at  [(45, 115), (91, 115), (91, 182), (45, 182)]\n",
      "norm(distance): 82.46915671906146\n",
      "couch  at  [(47, 113), (92, 113), (92, 181), (47, 181)]\n",
      "norm(distance): 81.78411918823478\n",
      "couch  at  [(53, 114), (96, 114), (96, 181), (53, 181)]\n",
      "norm(distance): 77.11901544051484\n",
      "couch  at  [(57, 115), (99, 115), (99, 182), (57, 182)]\n",
      "norm(distance): 73.56608449971561\n",
      "couch  at  [(63, 118), (104, 118), (104, 181), (63, 181)]\n",
      "norm(distance): 68.28804017144924\n",
      "couch  at  [(66, 114), (107, 114), (107, 182), (66, 182)]\n",
      "norm(distance): 66.51396709488667\n",
      "couch  at  [(73, 117), (112, 117), (112, 181), (73, 181)]\n",
      "norm(distance): 60.9728284522798\n",
      "couch  at  [(80, 115), (118, 115), (118, 181), (80, 181)]\n",
      "norm(distance): 56.40360398088395\n",
      "couch  at  [(82, 118), (119, 118), (119, 180), (82, 180)]\n",
      "norm(distance): 54.61072598312609\n",
      "couch  at  [(83, 115), (121, 115), (121, 180), (83, 180)]\n",
      "norm(distance): 54.45926673988878\n",
      "couch  at  [(84, 113), (121, 113), (121, 180), (84, 180)]\n",
      "norm(distance): 54.767766790402334\n",
      "couch  at  [(84, 112), (123, 112), (123, 182), (84, 182)]\n",
      "norm(distance): 53.69716825737088\n",
      "couch  at  [(83, 105), (123, 105), (123, 178), (83, 178)]\n",
      "norm(distance): 57.959724035595286\n",
      "couch  at  [(86, 115), (123, 115), (123, 180), (86, 180)]\n",
      "norm(distance): 52.62854243196273\n",
      "couch  at  [(84, 108), (125, 108), (125, 176), (84, 176)]\n",
      "norm(distance): 56.57735906586815\n",
      "couch  at  [(87, 113), (125, 113), (125, 181), (87, 181)]\n",
      "norm(distance): 51.91182546902915\n",
      "couch  at  [(89, 114), (126, 114), (126, 179), (89, 179)]\n",
      "norm(distance): 51.23389277168958\n",
      "couch  at  [(89, 115), (128, 115), (128, 181), (89, 181)]\n",
      "norm(distance): 49.45587095345968\n",
      "Reference object near focal center !!!\n"
     ]
    }
   ],
   "source": [
    "# Use stool_2 as reference object\n",
    "ref_obj = 62\n",
    "print(ref_obj,COCO_labels[ref_obj])\n",
    "Rtime = 0.05\n",
    "speed = 0.3\n",
    "\n",
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "for i in range(3):\n",
    "    rotate_left_2wheels(speed, Rtime)\n",
    "\n",
    "for i in range(100):\n",
    "    rotate_left_2wheels(speed, Rtime)\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=False) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "\n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "    \n",
    "    if obj_features is None:\n",
    "        continue\n",
    "    else:\n",
    "        Rtime = 0.01\n",
    "        speed = 0.29\n",
    "        norm_distance = np.linalg.norm(focal_center - object_center(obj_features))\n",
    "        print(COCO_labels[ref_obj], \" at \", obj_features)\n",
    "        print(\"norm(distance):\", norm_distance)\n",
    "        if  norm_distance < 50:\n",
    "            print(\"Reference object near focal center !!!\")\n",
    "            break\n",
    "        continue\n",
    " \n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271a46c55ee4c75b0306c5b233cb7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 couch [(163, 80), (263, 80), (263, 185), (163, 185)]\n",
      "couch 62 [(152, 105), (194, 177)]\n",
      "[(152, 105), (194, 105), (194, 177), (152, 177)]\n",
      "[[ 11 -25  69 -25  69   8  11   8]] 105.55567251455508\n",
      "Iteration  0\n",
      "\n",
      "Wheel speeds: [[6.45787053]\n",
      " [8.53331263]] (-0.5300455491019078, -0.5340570150006578)\n",
      "Robot speeds: [[ 0.24360673]\n",
      " [-0.5620989 ]]\n",
      "Orientation: 1.5707963267948966\n",
      "Depth: 1.8\n",
      "left wheel: 0.3870504205742865  right wheel: 0.3484734299624129\n",
      "couch 62 [(153, 110), (193, 179)]\n",
      "couch 62 [(149, 105), (189, 181)]\n",
      "[(149, 105), (189, 105), (189, 181), (149, 181)]\n",
      "[[ 14 -25  74 -25  74   4  14   4]] 112.36547512470189\n",
      "Iteration  2\n",
      "\n",
      "Wheel speeds: [[5.36206818]\n",
      " [7.40924428]] (0.4010914536555295, 0.3632349854161815)\n",
      "Robot speeds: [[ 0.20753383]\n",
      " [-0.55444353]]\n",
      "Orientation: 1.459311123001397\n",
      "Depth: 1.795640262516808\n",
      "left wheel: 0.36615695691406197  right wheel: 0.3281053565220173\n",
      "couch 62 [(145, 102), (188, 178)]\n",
      "vase 85 [(230, 16), (292, 96)]\n",
      "couch 62 [(140, 103), (182, 176)]\n",
      "[(140, 103), (182, 103), (182, 176), (140, 176)]\n",
      "[[ 23 -23  81 -23  81   9  23   9]] 124.09673645990857\n",
      "Iteration  4\n",
      "\n",
      "Wheel speeds: [[1.50362778]\n",
      " [4.12953888]] (0.3314863849935912, 0.29323118004235754)\n",
      "Robot speeds: [[ 0.09153896]\n",
      " [-0.71118425]]\n",
      "Orientation: 1.3438726735090765\n",
      "Depth: 1.7889481428081162\n",
      "left wheel: 0.3051958899324511  right wheel: 0.2695276335637359\n",
      "couch 62 [(136, 108), (178, 182)]\n",
      "couch 62 [(133, 100), (176, 179)]\n",
      "laptop 72 [(210, 3), (298, 107)]\n",
      "[(133, 100), (176, 100), (176, 179), (133, 179)]\n",
      "[[ 30 -20  87 -20  87   6  30   6]] 133.4541119636259\n",
      "Iteration  6\n",
      "\n",
      "Wheel speeds: [[-2.27804318]\n",
      " [ 0.34657258]] (0.2973329822801922, 0.2653621117512148)\n",
      "Robot speeds: [[-0.0313864 ]\n",
      " [-0.71083344]]\n",
      "Orientation: 1.2060816617987367\n",
      "Depth: 1.7834620313799316\n",
      "left wheel: 0.2545009426468025  right wheel: -0.279584976423853\n",
      "Reference object not detected!!!\n",
      "couch 62 [(110, 100), (153, 179)]\n",
      "[(110, 100), (153, 100), (153, 179), (110, 179)]\n",
      "[[ 53 -20 110 -20 110   6  53   6]] 175.1856158478772\n",
      "Iteration  8\n",
      "\n",
      "Wheel speeds: [[-12.69425706]\n",
      " [ -8.71661114]] (0.2545009426468025, -0.279584976423853)\n",
      "Robot speeds: [[-0.34792661]\n",
      " [-1.07727911]]\n",
      "Orientation: 1.1349983180701404\n",
      "Depth: 1.7847869577882032\n",
      "left wheel: -0.39045745604335375  right wheel: -0.46003911723044677\n",
      "couch 62 [(120, 116), (158, 179)]\n",
      "FPS: 3.6\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# robot pose - may need to be updated\n",
    "depth = 1.8\n",
    "orientation = math.pi/2\n",
    "\n",
    "# Control loop parameters\n",
    "gain = 1.3\n",
    "Rtime = 0.1  # The loop run at 8fps --> 0.125s duration\n",
    "num_iter = 10\n",
    "interval = 2\n",
    "\n",
    "no_motion = False  # Flag to disable motor (for debugging)\n",
    "debug = True\n",
    "\n",
    "# Use stool as reference object\n",
    "ref_obj = 62\n",
    "goal_features = create_feature_pts(mid_bbox_stool_2)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Run for fixed # of iterations\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=True) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "    \n",
    "    if obj_features is None:\n",
    "        print(\"Reference object not detected!!!\")\n",
    "        continue\n",
    "        \n",
    "    # bound reference object's feature points at goal pose in red\n",
    "    cv2.rectangle(image, goal_features[0], goal_features[2], RED, 2)\n",
    "    error = features_error(obj_features,goal_features)\n",
    "    error_norm = np.linalg.norm(error)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(obj_features)\n",
    "        print(error, error_norm)\n",
    "\n",
    "    if np.linalg.norm(error) < 10:\n",
    "        print (\"Goal point achieved!!!\")\n",
    "        break\n",
    "        \n",
    "    T = control2robot(wheel_radius, axle_length) # wheel speeds to robot velocities transform\n",
    "    H = robot2world(orientation)  # robot velocities to world frame transform\n",
    "    \n",
    "    # Image Jacobian based on 4 fp of reference object\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "    \n",
    "    # implement w = gain * pinv(LHT).error\n",
    "    J = np.dot(L,np.dot(H,T))\n",
    "    inv_J = np.linalg.pinv(J)\n",
    "    wheel_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "    robot_velocities = np.dot(T, wheel_velocities)\n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(\"Iteration \", i)\n",
    "        save_snapshot(image, diag_dir, i)\n",
    "        print ()\n",
    "        print(\"Wheel speeds:\", wheel_velocities, (w_l, w_r))\n",
    "        print(\"Robot speeds:\", robot_velocities)\n",
    "        print(\"Orientation:\", orientation)\n",
    "        print(\"Depth:\", depth)\n",
    "    \n",
    "    # limit robot translational speed to 0.9m/s\n",
    "    tranl_velocity = robot_velocities[0,0]\n",
    "    if abs(tranl_velocity) > 0.9:\n",
    "        robot_velocities[0,0] = tranl_velocity/abs(tranl_velocity) * 0.6\n",
    "        wheel_velocities = np.dot(np.linalg.pinv(T), robot_velocities)\n",
    "        print(\"Robot speed clamped.\")\n",
    "        print(\"Robot speeds:\", robot_velocities)\n",
    "    \n",
    "    w_r = omega2speed(wheel_velocities[0,0],wheel_calibration) \n",
    "    w_l = omega2speed(wheel_velocities[1,0],wheel_calibration) \n",
    "    \n",
    "    if i%interval == 0 and debug:\n",
    "        print(\"left wheel:\", w_l, \" right wheel:\", w_r)\n",
    "   \n",
    "    if no_motion is False:\n",
    "        robot.set_motors(w_l, w_r)\n",
    "        time.sleep(Rtime)\n",
    "        robot.stop()\n",
    "    \n",
    "    # Update robot's orientation\n",
    "    translation_velocity = robot_velocities[0,0]\n",
    "    angular_velocity = robot_velocities[1,0]\n",
    "    orientation += Rtime*angular_velocity\n",
    "    depth -= Rtime*translation_velocity*math.cos(orientation)\n",
    "    \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "\n",
    "image_widget.value = bgr8_to_jpeg(image)\n",
    "robot.stop()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print (\"FPS: {:.1f}\".format(num_iter/(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24360673]\n",
      " [-0.5620989 ]]\n"
     ]
    }
   ],
   "source": [
    "obj_features = [(152, 105), (194, 105), (194, 177), (152, 177)]\n",
    "error = np.array([[ 11, -25,  69, -25,  69,   8,  11,   8]])\n",
    "\n",
    "orientation = 1.5707963267948966\n",
    "depth = 1.8\n",
    "\n",
    "T = control2robot(wheel_radius, axle_length) # wheel speeds to robot velocities transform\n",
    "H = robot2world(orientation)  # robot velocities to world frame transform\n",
    "\n",
    "# Image Jacobian based on 4 fp of reference object\n",
    "UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "    \n",
    "# implement w = gain * pinv(LHT).error\n",
    "J = np.dot(L,np.dot(H,T))\n",
    "inv_J = np.linalg.pinv(J)\n",
    "\n",
    "wheel_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "robot_velocities = np.dot(T, wheel_velocities)\n",
    "\n",
    "print (robot_velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel_velocities = np.array([[-127.14279363], [-124.01202694]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [-0.00273215]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_velocities[0,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranl_velocity = robot_velocities[0,0]\n",
    "if abs(tranl_velocity) > 0.9:\n",
    "    robot_velocities[0,0] = tranl_velocity/abs(tranl_velocity) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [-0.00273215]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
