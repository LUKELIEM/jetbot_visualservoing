{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Based Visual Servoing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import camera calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Load COCO labels\n",
    "filename = \"coco_labels.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "COCO_labels = pickle.load(filehandler)\n",
    "\n",
    "# Load camera calibration data for undistort\n",
    "filename = \"calibration.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "camera_cal = pickle.load(filehandler)\n",
    "\n",
    "mtx = camera_cal['mtx']\n",
    "dist = camera_cal['dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('../Notebooks/object_following/ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up camera for object detection\n",
    "* Camera is set up for 300x300 pixel video\n",
    "* Use undistort() to undistort camera image prior to object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power up robot motor control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist, crop=False):\n",
    "    \"\"\"Undistort camera image based on calibration data\"\"\"\n",
    "    h,  w = img.shape[:2]\n",
    "    # print (h,w)\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    # undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image if asked\n",
    "    if crop:\n",
    "        x,y,w,h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "def create_feature_pts(bbox):\n",
    "    \"\"\" Return 4 feature points of bounding box \"\"\"\n",
    "    # extract bounding x and y coordinates\n",
    "    UL_fp, LR_fp = bbox\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "   \n",
    "    # return UL, UR, LR, LL feature points\n",
    "    return [(UL_fp_x, UL_fp_y), (LR_fp_x, UL_fp_y), (LR_fp_x, LR_fp_y), (UL_fp_x, LR_fp_y)]\n",
    "    \n",
    "def features_errors(currentFeatures, desiredFeatures):\n",
    "    \"\"\" Return feature points error vector \"\"\"\n",
    "    UL_current, UR_current, LR_current, LL_current = currentFeatures \n",
    "    UL_desired, UR_desired, LR_desired, LL_desired = desiredFeatures \n",
    "    \n",
    "    # calculate error for each feature point\n",
    "    UL_error = fp_error(UL_current, UL_desired)\n",
    "    error_vector = np.asarray(UL_error)\n",
    "    UR_error = fp_error(UR_current, UR_desired)\n",
    "    error_vector = np.concatenate((error_vector, UR_error), axis=None)\n",
    "    LR_error = fp_error(LR_current, LR_desired)\n",
    "    error_vector = np.concatenate((error_vector, LR_error), axis=None)\n",
    "    LL_error = fp_error(LL_current, LL_desired)\n",
    "    error_vector = np.concatenate((error_vector, LL_error), axis=None)\n",
    "\n",
    "    # return 1x8 error vector of UL, UR, LR, LL feature points\n",
    "    return np.reshape(error_vector, (1,-1))\n",
    "    \n",
    "    \n",
    "def fp_error(current, desired):\n",
    "    \"\"\" Return error of a feature point \"\"\"\n",
    "    current_x, current_y = current\n",
    "    desired_x, desired_y = desired\n",
    "    return (desired_x-current_x, desired_y-current_y)\n",
    "\n",
    "\n",
    "def image_Jacobian(fp, mtx, depth):\n",
    "    \"\"\" Generate image jacobiab L for a feature point \"\"\"\n",
    "    # focal lengths in pixel unit\n",
    "    f_u = mtx[0,0]\n",
    "    f_v = mtx[1,1]\n",
    "    c_u = mtx[0,2]\n",
    "    c_v = mtx[1,2]\n",
    "\n",
    "    # Estimated distance of reference object (m)\n",
    "    Z = depth\n",
    "\n",
    "    # Calculate J of feature point\n",
    "    u_raw, v_raw = fp\n",
    "    u = u_raw - c_u\n",
    "    v = v_raw - c_v    \n",
    "    \n",
    "    L = np.array([[-f_u/Z, 0, u/Z, u*v/f_u, -(f_u+u*u/f_u), v],\n",
    "                  [0, -f_v/Z, v/Z, f_v+v*v/f_v, -u*v/f_v, -u]])\n",
    "    return L\n",
    "\n",
    "\"\"\"\n",
    "def robot_jacobian(theta):\n",
    "    \n",
    "    return np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "\"\"\"\n",
    "\n",
    "def robot_jacobian(robot_angle, wheel_radius, axle_length):\n",
    "    \"\"\" calculate the robot jacobian \"\"\"\n",
    "    theta = robot_angle\n",
    "    l = axle_length\n",
    "    r = wheel_radius\n",
    "    H = np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "    T = np.array([[r/2, r/2],\n",
    "                  [r/l, -r/l]])\n",
    "    \n",
    "    return np.dot(H,T)\n",
    "\n",
    "def control2motion(wheel_radius, axle_length):\n",
    "    \"\"\" transform wheel speeds to robot motion in world frame \"\"\"\n",
    "    l = axle_length\n",
    "    r = wheel_radius\n",
    "\n",
    "    T = np.array([[r/2, r/2],\n",
    "                  [r/l, -r/l]])\n",
    "    \n",
    "    return T\n",
    "\n",
    "def robot2world(robot_angle):\n",
    "    \"\"\" calculate the robot jacobian \"\"\"\n",
    "    theta = robot_angle\n",
    "    H = np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "    return H\n",
    "\n",
    "def speed_limit(motion):\n",
    "    \"\"\" Clip wheel velocities \"\"\"\n",
    "    right_w = motion[0,0]\n",
    "    left_w = motion[1,0]\n",
    "    MOTION = 0.3\n",
    "    \n",
    "    max_abs = max(abs(right_w), abs(left_w))\n",
    "    min_abs = min(abs(right_w), abs(left_w))\n",
    "    \n",
    "    if max_abs > 1.0:\n",
    "        # Limit the peak forward velocity to 1.0\n",
    "        w_r = right_w/max_abs\n",
    "        w_l = left_w/max_abs\n",
    "    elif max_abs < 0.1:\n",
    "        # if velocities are below 0.1, set wheel speeds to zero\n",
    "        w_r = 0\n",
    "        w_l = 0\n",
    "    else:\n",
    "        if min_abs < 0.3:\n",
    "            # Scale velocities above 0.3\n",
    "            w_r = right_w*0.3/min_abs\n",
    "            w_l = left_w*0.3/min_abs\n",
    "        else:\n",
    "            w_r = right_w\n",
    "            w_l = left_w\n",
    "        \n",
    "    return w_l, w_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Image Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bbox_TV = [(102, 90), (161, 134)]\n",
    "\n",
    "pos1_bbox_TV = [(102, 90), (164, 135)]\n",
    "pos1_bbox_stool = [(168, 123), (200, 182)]\n",
    "\n",
    "pos2_bbox_TV = [(99, 79), (170, 128)]\n",
    "pos2_bbox_stool = [(171, 115), (211, 183)]\n",
    "\n",
    "pos2left_bbox_TV = [(136, 64), (218, 132)]\n",
    "pos2left_bbox_stool = [(215, 96), (283, 187)]\n",
    "\n",
    "pos2right_bbox_TV = [(51, 69), (134, 131)]\n",
    "pos2right_bbox_stool = [(131, 122), (164, 184)]\n",
    "\n",
    "pos3_bbox_TV = [(90, 72), (172, 127)]\n",
    "pos3_bbox_stool = [(172, 107), (219, 189)]\n",
    "\n",
    "beg_bbox_TV = [(72, 92), (136, 137)]\n",
    "mid_bbox_TV = [(54, 70), (134, 121)]\n",
    "mid_bbox_stool = [(175, 125), (216, 183)]\n",
    "end_bbox_stool = [(199, 88), (270, 187)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcf99e2fd7248bca9ae6b37ee05b21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop 72 [(72, 90), (133, 135)]\n",
      "couch 62 [(149, 130), (174, 181)]\n",
      "[(72, 90), (133, 135)]\n",
      "[(54, 70), (134, 121)]\n",
      "[[-18]\n",
      " [-20]\n",
      " [  1]\n",
      " [-20]\n",
      " [  1]\n",
      " [-14]\n",
      " [-18]\n",
      " [-14]]\n",
      "[[0.85879679]\n",
      " [2.8325448 ]]\n",
      "1.0 0.3031891269029517\n"
     ]
    }
   ],
   "source": [
    "display(widgets.HBox([image_widget]))\n",
    "depth = 2.0\n",
    "robot_theta = -math.pi/6\n",
    "wheel_radius = 0.0325\n",
    "axle_length = 0.12\n",
    "lamba = 10\n",
    "Rtime = 0.1\n",
    "\"\"\"\n",
    "# Use stool as reference object\n",
    "target = 62\n",
    "end_target_bbox_pixel = end_bbox_stool\n",
    "\"\"\"\n",
    "# Use TV as reference object\n",
    "target = 72\n",
    "end_target_bbox_pixel = mid_bbox_TV\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    undistort_image = undistort(camera.value, mtx, dist)\n",
    "    detections = model(undistort_image)\n",
    "\n",
    "     # draw all detections on image\n",
    "    for det in detections[0]:\n",
    "        label = COCO_labels[det['label']]\n",
    "        bbox = det['bbox']\n",
    "        bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                       (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "        cv2.rectangle(undistort_image, bbox_pixel[0], bbox_pixel[1], (255, 0, 0), 1)\n",
    "\n",
    "        print(label,det['label'], bbox_pixel)\n",
    "\n",
    "        # select detections that match selected class label\n",
    "        matching_detections = [d for d in detections[0] if d['label'] == target]\n",
    "\n",
    "        # get detection closest to center of field of view and draw it\n",
    "        det = closest_detection(matching_detections)\n",
    "\n",
    "        if det is not None:\n",
    "            bbox = det['bbox']\n",
    "            cv2.rectangle(undistort_image, (int(width * bbox[0]), int(width * bbox[1])),\\\n",
    "                                    (int(width * bbox[2]), int(height * bbox[3])), (0, 255, 0), 2)\n",
    "            cv2.rectangle(undistort_image, end_target_bbox_pixel[0], end_target_bbox_pixel[1], \\\n",
    "                          (0, 0, 255), 2)\n",
    "            target_bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                       (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "\n",
    "    image_widget.value = bgr8_to_jpeg(undistort_image)\n",
    "\n",
    "    beg_feature_pts = create_feature_pts(target_bbox_pixel)\n",
    "    end_feature_pts = create_feature_pts(end_target_bbox_pixel)\n",
    "    print(target_bbox_pixel)\n",
    "    print(end_target_bbox_pixel)\n",
    "\n",
    "    error = features_errors(beg_feature_pts,end_feature_pts)\n",
    "    print (error.T)\n",
    "\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = beg_feature_pts\n",
    "\n",
    "    # Generate image jacobian L\n",
    "    L = np.vstack((image_Jacobian(UL_fp, mtx, depth), image_Jacobian(UR_fp, mtx, depth), \\\n",
    "              image_Jacobian(LR_fp, mtx, depth), image_Jacobian(LL_fp, mtx, depth)))\n",
    "\n",
    "    J = robot_jacobian(robot_theta, wheel_radius, axle_length)\n",
    "\n",
    "    wheel_motion = lamba*np.dot(np.linalg.pinv(np.dot(L,J)), error.T)\n",
    "    print(wheel_motion)\n",
    "    w_l, w_r = speed_limit(wheel_motion)\n",
    "    print(w_l, w_r)\n",
    "\n",
    "    Rtime = 0.1\n",
    "\n",
    "    robot.set_motors(w_l, w_r)\n",
    "    time.sleep(Rtime)\n",
    "    robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05444397]\n",
      " [-0.00192063]]\n"
     ]
    }
   ],
   "source": [
    "T = control2motion(wheel_radius, axle_length)\n",
    "robot_motion = np.dot(T, wheel_motion)\n",
    "\n",
    "print(robot_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17554929852485657,\n",
       " 0.21843597292900085,\n",
       " 0.45806071162223816,\n",
       " 0.4206964671611786]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
