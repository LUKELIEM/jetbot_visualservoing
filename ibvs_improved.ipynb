{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import bgr8_to_jpeg\n",
    "from jetbot import ObjectDetector\n",
    "from jetbot import Camera\n",
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectDetector('../Notebooks/object_following/ssd_mobilenet_v2_coco.engine')\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created because they already exist\n"
     ]
    }
   ],
   "source": [
    "# Load COCO labels\n",
    "filename = \"coco_labels.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "COCO_labels = pickle.load(filehandler)\n",
    "\n",
    "# Load camera calibration data for undistort\n",
    "filename = \"calibration.dat\"\n",
    "filehandler = open(filename, 'rb')\n",
    "camera_cal = pickle.load(filehandler)\n",
    "mtx = camera_cal['mtx']\n",
    "dist = camera_cal['dist']\n",
    "f_u = mtx[0,0]   # focal center coordinates\n",
    "f_v = mtx[1,1]\n",
    "focal_center = np.array([f_u, f_v])\n",
    "\n",
    "# Mapping between set_motor \"speed\" and measured wheel angular velocity \"omega\"\n",
    "# for 0.1 second motor running time\n",
    "wheel_calibration = {\n",
    "    \"speed\": [0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    \"omega\": [0.0, 3.85, 9.23, 15.0, 25.8, 29.2, 35.4]\n",
    "}\n",
    "\n",
    "# Open Image Widget\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "BLUE = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "\n",
    "diag_dir = 'diagnostics'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(diag_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bbox for TV and stool at various camera poses\n",
    "# For (0,0,0) to (1,0,0)\n",
    "beg_bbox_TV = [(72, 92), (136, 137)]  # Pose (0,0,0)\n",
    "mid_bbox_TV = [(33, 69), (114, 124)]  # Pose ~(0.5,0,0)\n",
    "end_bbox_stool = [(175, 87), (238, 186)]   # Pose (1.0,0,0)\n",
    "\n",
    "# Bbox for 2nd stool at various camera poses\n",
    "# For (1,0,0) to (2,0,pi)\n",
    "mid_bbox_chair = [(159, 69), (240, 184)]  # midpoint to Pose (1,2,0)\n",
    "end_bbox_plant = [(59, 76), (155, 187)]   # Pose (1,2,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist, crop=False):\n",
    "    \"\"\"Undistort camera image based on calibration data\"\"\"\n",
    "    h,w = img.shape[:2]\n",
    "    # print (h,w)\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    # undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image (optional)\n",
    "    if crop:\n",
    "        x,y,w,h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def draw_bbox(img, width, height, bbox, color, line_width):\n",
    "    bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                  (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "    cv2.rectangle(img, bbox_pixel[0], bbox_pixel[1], color, line_width)\n",
    "    return bbox_pixel\n",
    "\n",
    "def display_detected(img, detections, width, height, debug=False):\n",
    "    \"\"\" put blue bounding boxes on detected objects on image \"\"\"\n",
    "    \n",
    "    for det in detections[0]:\n",
    "        label = COCO_labels[det['label']-1]\n",
    "        bbox = det['bbox']\n",
    "        bbox_pixel = draw_bbox(img, width, height, bbox, BLUE, 1)\n",
    "        if debug:\n",
    "            print(label,det['label'], bbox_pixel)\n",
    "    return\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def object_center(obj_features):\n",
    "    \"\"\"Computes the center x, y coordinates of the object using its feature points\"\"\"\n",
    "    UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "    center_x = (UL_fp_x + LR_fp_x) / 2.0 - 0.5\n",
    "    center_y = (UL_fp_y + LR_fp_y) / 2.0 - 0.5\n",
    "    return np.array([center_x, center_y])\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections, debug= False):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if debug:\n",
    "            print(center)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "def create_feature_pts(bbox):\n",
    "    \"\"\" Return 4 feature points from a bounding box \"\"\"\n",
    "    # extract bounding x and y coordinates\n",
    "    UL_fp, LR_fp = bbox\n",
    "    UL_fp_x, UL_fp_y = UL_fp\n",
    "    LR_fp_x, LR_fp_y = LR_fp\n",
    "   \n",
    "    # return UL(upper left), UR(upper right), LR(lower right), LL(lower left) feature points\n",
    "    return [(UL_fp_x, UL_fp_y), (LR_fp_x, UL_fp_y), (LR_fp_x, LR_fp_y), (UL_fp_x, LR_fp_y)]\n",
    "\n",
    "def generate_ref_obj_features(ref_obj, img, detections, width, height, debug=False):\n",
    "    \"\"\" Find reference object in detected objects and generate 4 feature points \"\"\"\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == ref_obj]\n",
    "\n",
    "    # get detection closest to center of field of view and draw it (if model detects multiple\n",
    "    # reference objects)\n",
    "    det = closest_detection(matching_detections)\n",
    "\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        # bound reference object in green\n",
    "        draw_bbox(img, width, height, bbox, GREEN, 1)\n",
    "        # convert to pixel units\n",
    "        bbox_pixel = [(int(width * bbox[0]), int(height * bbox[1])), \n",
    "                       (int(width * bbox[2]), int(height * bbox[3]))]\n",
    "        return create_feature_pts(bbox_pixel) # return 4 feature points of bounding box\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def fp_error(current, goal):\n",
    "    \"\"\" Return error of a feature point \"\"\"\n",
    "    current_x, current_y = current\n",
    "    goal_x, goal_y = goal\n",
    "    # Use Corke's convention of (p*-p) --> gain is a +ve number\n",
    "    return (goal_x-current_x, goal_y-current_y)  \n",
    "\n",
    "def features_error(currentFeatures, goalFeatures):\n",
    "    \"\"\" Return feature points error vector \"\"\"\n",
    "    UL_current, UR_current, LR_current, LL_current = currentFeatures \n",
    "    UL_goal, UR_goal, LR_goal, LL_goal = goalFeatures \n",
    "    \n",
    "    # calculate error for each feature point\n",
    "    UL_error = fp_error(UL_current, UL_goal)\n",
    "    error_vector = np.asarray(UL_error)\n",
    "    UR_error = fp_error(UR_current, UR_goal)\n",
    "    error_vector = np.concatenate((error_vector, UR_error), axis=None)\n",
    "    LR_error = fp_error(LR_current, LR_goal)\n",
    "    error_vector = np.concatenate((error_vector, LR_error), axis=None)\n",
    "    LL_error = fp_error(LL_current, LL_goal)\n",
    "    error_vector = np.concatenate((error_vector, LL_error), axis=None)\n",
    "\n",
    "    # return 1x8 error vector of UL, UR, LR, LL feature points\n",
    "    return np.reshape(error_vector, (1,-1))\n",
    "\n",
    "def image_jacobian(fp, mtx, depth):\n",
    "    \"\"\" Generate image jacobiab L for a feature point \"\"\"\n",
    "    # focal lengths in pixel unit\n",
    "    f_u = mtx[0,0]\n",
    "    f_v = mtx[1,1]\n",
    "    c_u = mtx[0,2]\n",
    "    c_v = mtx[1,2]\n",
    "\n",
    "    # Estimated distance of reference object (m)\n",
    "    Z = depth\n",
    "\n",
    "    # Calculate J of feature point\n",
    "    u_raw, v_raw = fp\n",
    "    u = u_raw - c_u\n",
    "    v = v_raw - c_v    \n",
    "    \n",
    "    L = np.array([[-f_u/Z, 0,      u/Z, u*v/f_u,     -(f_u+u*u/f_u), v],\n",
    "                  [0,      -f_v/Z, v/Z, f_v+v*v/f_v, -u*v/f_v,      -u]])\n",
    "    return L\n",
    "\n",
    "def robot2world(robot_orientation):\n",
    "    \"\"\" calculate the robot jacobian \"\"\"\n",
    "    theta = robot_orientation\n",
    "    \n",
    "    \"\"\"\n",
    "    This may be incorrect\n",
    "    return np.array([[math.cos(theta),0],\n",
    "                  [math.sin(theta),0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([[0,0],\n",
    "                  [0,0],\n",
    "                  [1,0],\n",
    "                  [0,0],\n",
    "                  [0,-1],\n",
    "                  [0,0]])\n",
    "\n",
    "def control2robot(wheel_radius, axle_length):\n",
    "    \"\"\" transform wheel speeds to robot motion in world frame \"\"\"\n",
    "    l = axle_length\n",
    "    r = wheel_radius\n",
    "\n",
    "    return np.array([[r/2, r/2],\n",
    "                  [r/l, -r/l]])\n",
    "\n",
    "def save_snapshot(img, directory, name, i):\n",
    "    image_path = os.path.join(directory, 'detect_'+name+str(i+1)+'.jpg')\n",
    "    cv2.imwrite(image_path, img) \n",
    "    return\n",
    "\n",
    "def omega2speed(in_val, mapping):\n",
    "    \"\"\" Map wheel angular speed to motor speed setting based on a calibration mapping \"\"\"\n",
    "    \n",
    "    if in_val < 0:\n",
    "        sign = -1\n",
    "        in_val = abs(in_val)\n",
    "    else:\n",
    "        sign = 1\n",
    "        \n",
    "    out_lower = 0\n",
    "    in_lower = 0\n",
    "    out_val = 0\n",
    "\n",
    "    for i, in_upper in enumerate(mapping[\"omega\"]):\n",
    "        # print (i, in_upper)\n",
    "        if in_val < in_upper:\n",
    "            out_upper = mapping[\"speed\"][i]\n",
    "            out_val = out_lower + (in_val - in_lower)/(in_upper - in_lower) \\\n",
    "                *(out_upper-out_lower)\n",
    "            # print(\"yes\", out_val)\n",
    "            break\n",
    "        else:\n",
    "            # print(\"no\")\n",
    "            out_lower = mapping[\"speed\"][i]\n",
    "            in_lower = in_upper\n",
    "            \n",
    "    if out_val is 0:\n",
    "        print (\"Input is too high!!!\", in_val)\n",
    "        out_val = 0\n",
    "        \n",
    "    return sign*out_val\n",
    "\n",
    "def rotate_left_2wheels(speed, Rtime):\n",
    "    \n",
    "    robot.set_motors(-speed, speed)\n",
    "    time.sleep(Rtime)\n",
    "    robot.stop()\n",
    "    \n",
    "    return\n",
    "\n",
    "def clamp(wheel_velocities, upper_limit, lower_limit, T, debug=False):\n",
    "    \"\"\" Put limits on motor speed \"\"\"\n",
    "    \n",
    "    robot_velocities = np.dot(T, wheel_velocities)  # get (tranl_vel, ang_vel)\n",
    "    tranl_velocity = robot_velocities[0,0]\n",
    "    \n",
    "    # Set lower limit on translational speed to 0.15m/s (motor setting 0.3)\n",
    "    if abs(tranl_velocity) < lower_limit:\n",
    "        robot_velocities[0,0] = tranl_velocity/abs(tranl_velocity) * lower_limit\n",
    "        if debug:\n",
    "            print(\"Robot speed boosted\", robot_velocities) \n",
    "    # Set upper limit on translational speed to 0.49m/s (motor setting 0.5)\n",
    "    elif abs(tranl_velocity) > upper_limit:\n",
    "        robot_velocities[0,0] = tranl_velocity/abs(tranl_velocity) * upper_limit\n",
    "        if debug:\n",
    "            print(\"Robot speed limited\", robot_velocities)\n",
    "            \n",
    "    ang_velocity = robot_velocities[1,0]\n",
    "    ang_upper_limit = 0.5\n",
    "    if abs(ang_velocity) > ang_upper_limit:\n",
    "        robot_velocities[1,0] = ang_velocity/abs(ang_velocity) * ang_upper_limit\n",
    "        if debug:\n",
    "            print(\"Rotational speed limited\", robot_velocities)\n",
    "            \n",
    "    # return clamped wheel velocities\n",
    "    return np.dot(np.linalg.pinv(T), robot_velocities)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBVS Main Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibvs_control(robot_params, control_params):\n",
    "    \"\"\" Control loop for IBVS \"\"\"\n",
    "    \n",
    "    # Load control loop parameters\n",
    "    gain = control_params[\"gain\"]\n",
    "    Rtime = control_params[\"Rtime\"]\n",
    "    num_iter = control_params[\"num_iter\"]\n",
    "    interval = control_params[\"interval\"]\n",
    "    no_motion = control_params[\"no_motion\"]\n",
    "    debug = goal_bbox = control_params[\"debug\"]\n",
    "    ref_obj = control_params[\"ref_obj\"]\n",
    "    obj_name = control_params[\"obj_name\"]\n",
    "    goal_bbox = control_params[\"goal_bbox\"]\n",
    "    error_window = control_params[\"error_window\"]\n",
    "    speed_lower_limit = control_params[\"speed_lower\"]\n",
    "    speed_upper_limit = control_params[\"speed_upper\"]\n",
    "    \n",
    "    # load robot control parameters\n",
    "    depth = robot_params[\"depth\"]\n",
    "    orientation = robot_params[\"orientation\"]\n",
    "    wheel_radius = robot_params[\"wheel_radius\"]\n",
    "    axle_length = robot_params[\"axle_length\"]\n",
    "    \n",
    "    goal_features = create_feature_pts(goal_bbox)\n",
    "    print(\"Tracking\", COCO_labels[ref_obj],\" to \", goal_features)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        print(\"Iteration \", i)\n",
    "        \n",
    "        \"\"\" Grab camera image, undistort and detect objects \"\"\"\n",
    "        image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "        detections = model(image) # Use SSD model to detect objects\n",
    "        display_detected(image, detections, width, height, debug) # put bounding boxes on detected objects\n",
    "        \n",
    "        \"\"\" If ref object is detected, bound it in green box \"\"\"\n",
    "        obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "    \n",
    "        if obj_features is None:\n",
    "            print(\"Reference object not detected!!!\")\n",
    "            image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "            continue\n",
    "        \n",
    "        \"\"\" Generate error vector (goal-current) \"\"\"\n",
    "        # Paint ref object's bbox at robot's goal pose in red\n",
    "        cv2.rectangle(image, goal_features[0], goal_features[2], RED, 2)\n",
    "        error = features_error(obj_features,goal_features)\n",
    "        error_norm = np.linalg.norm(error)\n",
    "    \n",
    "        if i%interval == 0 and debug:\n",
    "            save_snapshot(image, diag_dir, obj_name, i)  # save snap shot\n",
    "            print (\"Ref Object:\", obj_features)\n",
    "            print(\"Error:\", error, error_norm)\n",
    "\n",
    "        if error_norm < error_window:  # exit control loop if error is within acceptable window\n",
    "            print (\"Goal point achieved!!!\")\n",
    "            break\n",
    "        \n",
    "        image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "        \n",
    "        \"\"\" Implementation of IBVS control: w = gain*pseudo_inv(LHT).error \"\"\"        \n",
    "        # T transforms wheel angular velocities (R,L) to robot velocities (translation, angular)\n",
    "        T = control2robot(wheel_radius, axle_length) \n",
    "        # H transform robot velocities to world frame velocities (v_x,v_y,v_z, w_x,w_y, w_z)\n",
    "        H = robot2world(orientation)  \n",
    "        # Image Jacobian L - formed by stacking image jacobians of 4 fp of the ref object\n",
    "        UL_fp, UR_fp, LR_fp, LL_fp = obj_features\n",
    "        L = np.vstack((image_jacobian(UL_fp, mtx, depth), image_jacobian(UR_fp, mtx, depth), \\\n",
    "              image_jacobian(LR_fp, mtx, depth), image_jacobian(LL_fp, mtx, depth)))\n",
    "        \n",
    "        # pinv(LHT) Approach \n",
    "        # implement w = gain * pinv(LHT).error\n",
    "        # J = np.dot(L,np.dot(H,T))\n",
    "        # inv_J = np.linalg.pinv(J)\n",
    "        # unclamped_velocities = gain * np.dot(np.linalg.pinv(J), error.T)\n",
    "        \n",
    "        # Step-by-step pinv() Approach\n",
    "        inv_L = np.linalg.pinv(L)\n",
    "        world_velocities = np.dot(inv_L, error.T)\n",
    "\n",
    "        inv_H = np.linalg.pinv(H)\n",
    "        robot_velocities = np.dot(inv_H, world_velocities)\n",
    "\n",
    "        inv_T = np.linalg.pinv(T)\n",
    "        unclamped_velocities = np.dot(inv_T, robot_velocities)\n",
    "\n",
    "        \"\"\" Clamp motor setting to (0.3-0.5) \"\"\"\n",
    "        wheel_velocities = clamp(unclamped_velocities, speed_upper_limit, \\\n",
    "                                 speed_lower_limit, T, debug) \n",
    "        robot_velocities = np.dot(T, wheel_velocities)\n",
    "        \n",
    "        \n",
    "        \"\"\" Map wheel angular velocities to motor setting, then run motors \"\"\" \n",
    "        w_r = omega2speed(wheel_velocities[0,0],wheel_calibration) \n",
    "        w_l = omega2speed(wheel_velocities[1,0],wheel_calibration)\n",
    "        \n",
    "        if no_motion is False:\n",
    "            robot.set_motors(w_l, w_r)  # left, right\n",
    "            time.sleep(Rtime)\n",
    "            robot.stop()\n",
    "       \n",
    "        \"\"\" Update robot's depth and orientation \"\"\" \n",
    "        transl_velocity = robot_velocities[0,0]\n",
    "        ang_velocity = robot_velocities[1,0]\n",
    "        # depth = online_est()  TBD\n",
    "        \n",
    "        if i%interval == 0 and debug:\n",
    "            print(\"Unclamped robot Velocities:\", unclamped_velocities)\n",
    "            print(\"Clamped wheel Velocities:\", wheel_velocities, (w_l, w_r))\n",
    "            print(\"Clamped robot Velocities:\", robot_velocities)\n",
    "            print(\"Depth:\", depth)\n",
    "            \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image        \n",
    "    save_snapshot(image, diag_dir, obj_name, i)    # save the last image\n",
    "    end = time.perf_counter()\n",
    "    print (\"FPS: {:.1f}\".format(i/(end-start)))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0,0,0) --> (1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2278d467d4414a8aa1645097934ee108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking laptop  to  [(33, 69), (114, 69), (114, 124), (33, 124)]\n",
      "Iteration  0\n",
      "Iteration  1\n",
      "Iteration  2\n",
      "Iteration  3\n",
      "Iteration  4\n",
      "Iteration  5\n",
      "Iteration  6\n",
      "Iteration  7\n",
      "Iteration  8\n",
      "Iteration  9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "Iteration  16\n",
      "Iteration  17\n",
      "Iteration  18\n",
      "Iteration  19\n",
      "Iteration  20\n",
      "Iteration  21\n",
      "Iteration  22\n",
      "Iteration  23\n",
      "Iteration  24\n",
      "Iteration  25\n",
      "Iteration  26\n",
      "Iteration  27\n",
      "Iteration  28\n",
      "Iteration  29\n",
      "Iteration  30\n",
      "Iteration  31\n",
      "Iteration  32\n",
      "Goal point achieved!!!\n",
      "FPS: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "robot_params = {\n",
    "    \"depth\": 2.0,\n",
    "    \"orientation\": 0,\n",
    "    \"wheel_radius\": 0.0325,\n",
    "    \"axle_length\": 0.12\n",
    "}\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": 0.03,\n",
    "    \"Rtime\": 0.1, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 3,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 72,  # Use TV as reference object\n",
    "    \"obj_name\": \"TV\",\n",
    "    \"goal_bbox\": mid_bbox_TV,  # This should get the robot to ~(0.5,0,0) \n",
    "    \"error_window\": 15,\n",
    "    \"speed_lower\": 0.14,  # This ensures motor settings > ~0.3\n",
    "    \"speed_upper\": 0.25  # This ensures motor settings > ~0.5\n",
    "}\n",
    "\n",
    "ibvs_control(robot_params, control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e8adef1a67487586dc231b4bff5a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking couch  to  [(175, 87), (238, 87), (238, 186), (175, 186)]\n",
      "Iteration  0\n",
      "Iteration  1\n",
      "Iteration  2\n",
      "Iteration  3\n",
      "Iteration  4\n",
      "Iteration  5\n",
      "Iteration  6\n",
      "Iteration  7\n",
      "Iteration  8\n",
      "Iteration  9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "Iteration  16\n",
      "Iteration  17\n",
      "Iteration  18\n",
      "Iteration  19\n",
      "Iteration  20\n",
      "Iteration  21\n",
      "Goal point achieved!!!\n",
      "FPS: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "robot_params = {\n",
    "    \"depth\": 1.5,\n",
    "    \"orientation\": 0,\n",
    "    \"wheel_radius\": 0.0325,\n",
    "    \"axle_length\": 0.12\n",
    "}\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": 0.03,\n",
    "    \"Rtime\": 0.1, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 50,\n",
    "    \"interval\": 2,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 62,  # Use TV as reference object\n",
    "    \"obj_name\": \"stool\",\n",
    "    \"goal_bbox\": end_bbox_stool,  # This should get the robot to ~(1,0,0) \n",
    "    \"error_window\": 12,\n",
    "    \"speed_lower\": 0.14,  # This ensures motor settings > ~0.3\n",
    "    \"speed_upper\": 0.20  # This ensures motor settings > ~0.5\n",
    "}\n",
    "\n",
    "ibvs_control(robot_params, control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1,0,0) --> (1,2,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_n_detect(control_param):\n",
    "    \"\"\" The robot rotates left in place until a ref object is close to its focal center \"\"\"\n",
    "\n",
    "    # Load control loop parameters\n",
    "    Rtime_course = control_params[\"Rtime_course\"]\n",
    "    Rtime_fine = control_params[\"Rtime_fine\"]\n",
    "    num_iter = control_params[\"num_iter\"]\n",
    "    interval = control_params[\"interval\"]\n",
    "    debug = control_params[\"debug\"]\n",
    "    ref_obj = control_params[\"ref_obj\"]\n",
    "    obj_name = control_params[\"obj_name\"]\n",
    "    error_window = control_params[\"error_window\"]\n",
    "    speed = control_params[\"speed\"]    \n",
    "\n",
    "    print(\"Looking for \", COCO_labels[ref_obj], \"(\", ref_obj, \")\")\n",
    "    Rtime = Rtime_course  # rotate is bigger steps\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        rotate_left_2wheels(speed, Rtime)  # rotate left by 1 step\n",
    "        \n",
    "        \"\"\" Identify ref object amongst detected objects \"\"\"\n",
    "        image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "        detections = model(image) # Use SSD model to detect objects\n",
    "        display_detected(image, detections, width, height, debug) # put bounding boxes on detected objects\n",
    "    \n",
    "        # Detect reference object in camera image and place green bounding box around it\n",
    "        obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "        \n",
    "        if i%interval == 0 and debug:\n",
    "            print(COCO_labels[ref_obj], \" identified at:\", obj_features)\n",
    "\n",
    "        # update image widget with camera image\n",
    "        image_widget.value = bgr8_to_jpeg(image)  \n",
    "        \n",
    "        \"\"\" Stop rotating if ref object is close to focal center \"\"\"\n",
    "        if obj_features is None:\n",
    "            continue\n",
    "        else:\n",
    "            Rtime = Rtime_fine # rotate in finer steps\n",
    "            \n",
    "            # Calculate distance of ref obj from focal center\n",
    "            norm_distance = np.linalg.norm(focal_center - object_center(obj_features))\n",
    "            print(COCO_labels[ref_obj], \" identified! Distance from focal center:\", norm_distance)\n",
    "            if  norm_distance < error_window:\n",
    "                print(\"Reference object near focal center !!!\")\n",
    "                break   # exit loop if distance within error window\n",
    "            continue\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65f9ed8a43142dc99f4385870f8201a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for  sheep ( 19 )\n",
      "sheep  identified! Distance from focal center: 100.428282787648\n",
      "sheep  identified! Distance from focal center: 91.1786880733113\n",
      "sheep  identified! Distance from focal center: 74.14989166019066\n",
      "Reference object near focal center !!!\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": None,\n",
    "    \"Rtime_course\": 0.04, # The loop run at 8fps --> 0.125s duration\n",
    "    \"Rtime_fine\": 0.02, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 2,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 19,  # Use horse as reference object\n",
    "    \"obj_name\": \"horse\",\n",
    "    \"goal_bbox\": None,  # This orients the robot towards a chair, the next ref object\n",
    "    \"error_window\": 80,\n",
    "    \"speed\": 0.31\n",
    "}\n",
    "\n",
    "rotate_n_detect(control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e929ed1f44348883704b097e94478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking couch  to  [(159, 69), (240, 69), (240, 184), (159, 184)]\n",
      "Iteration  0\n",
      "Iteration  1\n",
      "Iteration  2\n",
      "Iteration  3\n",
      "Iteration  4\n",
      "Iteration  5\n",
      "Iteration  6\n",
      "Iteration  7\n",
      "Iteration  8\n",
      "Iteration  9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "Iteration  16\n",
      "Iteration  17\n",
      "Iteration  18\n",
      "Iteration  19\n",
      "Iteration  20\n",
      "Iteration  21\n",
      "Iteration  22\n",
      "Iteration  23\n",
      "Iteration  24\n",
      "Iteration  25\n",
      "Iteration  26\n",
      "Iteration  27\n",
      "Iteration  28\n",
      "Iteration  29\n",
      "Iteration  30\n",
      "Goal point achieved!!!\n",
      "FPS: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "robot_params = {\n",
    "    \"depth\": 2.0,\n",
    "    \"orientation\": 0,\n",
    "    \"wheel_radius\": 0.0325,\n",
    "    \"axle_length\": 0.12\n",
    "}\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": 0.02,\n",
    "    \"Rtime\": 0.1, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 5,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 62,  # Use chair as reference object\n",
    "    \"obj_name\": \"chair\",\n",
    "    \"goal_bbox\": mid_bbox_chair,  # This should get the robot to ~(0.5,0,0) \n",
    "    \"error_window\": 15,\n",
    "    \"speed_lower\": 0.14,  # This ensures motor settings > ~0.3\n",
    "    \"speed_upper\": 0.28  # This ensures motor settings > ~0.5\n",
    "}\n",
    "\n",
    "ibvs_control(robot_params, control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387dd91db4e34f75b5a38ad946eaee79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for  bed ( 64 )\n",
      "bed  identified! Distance from focal center: 74.00458390995783\n",
      "bed  identified! Distance from focal center: 62.64900514695552\n",
      "bed  identified! Distance from focal center: 55.20625902902441\n",
      "bed  identified! Distance from focal center: 53.33532196617905\n",
      "bed  identified! Distance from focal center: 46.26608691710758\n",
      "Reference object near focal center !!!\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": None,\n",
    "    \"Rtime_course\": 0.03, # The loop run at 8fps --> 0.125s duration\n",
    "    \"Rtime_fine\": 0.015, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 2,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 64,  # Use plant as reference object\n",
    "    \"obj_name\": \"plant\",\n",
    "    \"goal_bbox\": None,  # This orients the robot towards a chair, the next ref object\n",
    "    \"error_window\": 50,\n",
    "    \"speed\": 0.31\n",
    "}\n",
    "\n",
    "rotate_n_detect(control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77bfdf5802406cb6e86b363cca38b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking bed  to  [(59, 76), (155, 76), (155, 187), (59, 187)]\n",
      "Iteration  0\n",
      "chair 62 [(192, 67), (297, 191)]\n",
      "potted plant 64 [(93, 113), (146, 176)]\n",
      "Ref Object: [(93, 113), (146, 113), (146, 176), (93, 176)]\n",
      "Error: [[-34 -37   9 -37   9  11 -34  11]] 73.85120175054702\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.09731396]]\n",
      "Unclamped robot Velocities: [[46.85212848]\n",
      " [47.21144158]]\n",
      "Clamped wheel Velocities: [[8.12803576]\n",
      " [8.48734886]] (0.3861960754240785, 0.37951739326336936)\n",
      "Clamped robot Velocities: [[ 0.27      ]\n",
      " [-0.09731396]]\n",
      "Depth: 2.0\n",
      "Iteration  1\n",
      "chair 62 [(177, 31), (297, 191)]\n",
      "potted plant 64 [(91, 120), (146, 178)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.35276242]]\n",
      "Iteration  2\n",
      "chair 62 [(179, 50), (296, 195)]\n",
      "potted plant 64 [(88, 117), (145, 178)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.26982102]]\n",
      "Iteration  3\n",
      "potted plant 64 [(93, 114), (146, 177)]\n",
      "chair 62 [(177, 6), (297, 190)]\n",
      "vase 86 [(110, 154), (134, 177)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.09825004]]\n",
      "Iteration  4\n",
      "Reference object not detected!!!\n",
      "Iteration  5\n",
      "potted plant 64 [(89, 117), (145, 179)]\n",
      "Ref Object: [(89, 117), (145, 117), (145, 179), (89, 179)]\n",
      "Error: [[-30 -41  10 -41  10   8 -30   8]] 74.09453421137081\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.15217809]]\n",
      "Unclamped robot Velocities: [[49.09834625]\n",
      " [48.5364579 ]]\n",
      "Clamped wheel Velocities: [[8.58863648]\n",
      " [8.02674813]] (0.37763472366835094, 0.388078745019097)\n",
      "Clamped robot Velocities: [[0.27      ]\n",
      " [0.15217809]]\n",
      "Depth: 2.0\n",
      "Iteration  6\n",
      "potted plant 64 [(81, 114), (139, 178)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.14781692]]\n",
      "Iteration  7\n",
      "potted plant 64 [(87, 116), (145, 179)]\n",
      "Robot speed limited [[0.27     ]\n",
      " [0.2082518]]\n",
      "Iteration  8\n",
      "potted plant 64 [(85, 114), (142, 179)]\n",
      "person 2 [(158, 0), (300, 211)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.04476551]]\n",
      "Iteration  9\n",
      "potted plant 64 [(84, 114), (143, 180)]\n",
      "chair 62 [(160, 2), (291, 217)]\n",
      "background 1 [(167, 4), (299, 222)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.10288189]]\n",
      "Iteration  10\n",
      "potted plant 64 [(91, 116), (147, 180)]\n",
      "chair 62 [(178, 5), (300, 187)]\n",
      "vase 86 [(106, 150), (132, 177)]\n",
      "Ref Object: [(91, 116), (147, 116), (147, 180), (91, 180)]\n",
      "Error: [[-32 -40   8 -40   8   7 -32   7]] 73.98648525237566\n",
      "Robot speed limited [[0.27     ]\n",
      " [0.0397568]]\n",
      "Unclamped robot Velocities: [[45.266924  ]\n",
      " [45.12012965]]\n",
      "Clamped wheel Velocities: [[8.38108948]\n",
      " [8.23429513]] (0.38149247462459634, 0.3842209940628516)\n",
      "Clamped robot Velocities: [[0.27     ]\n",
      " [0.0397568]]\n",
      "Depth: 2.0\n",
      "Iteration  11\n",
      "potted plant 64 [(99, 116), (160, 179)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.32543707]]\n",
      "Iteration  12\n",
      "potted plant 64 [(97, 112), (164, 175)]\n",
      "vase 86 [(124, 150), (149, 179)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.49832288]]\n",
      "Iteration  13\n",
      "potted plant 64 [(100, 112), (166, 174)]\n",
      "Robot speed limited [[0.27     ]\n",
      " [0.4721652]]\n",
      "Iteration  14\n",
      "potted plant 64 [(107, 109), (172, 179)]\n",
      "vase 86 [(124, 151), (155, 178)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.09498931]]\n",
      "Iteration  15\n",
      "potted plant 64 [(113, 105), (176, 179)]\n",
      "Ref Object: [(113, 105), (176, 105), (176, 179), (113, 179)]\n",
      "Error: [[-54 -29 -21 -29 -21   8 -54   8]] 92.32551110067033\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.00919581]]\n",
      "Unclamped robot Velocities: [[31.60930759]\n",
      " [31.64326134]]\n",
      "Clamped wheel Velocities: [[8.29071543]\n",
      " [8.32466918]] (0.38317228964657624, 0.3825411790408717)\n",
      "Clamped robot Velocities: [[ 0.27      ]\n",
      " [-0.00919581]]\n",
      "Depth: 2.0\n",
      "Iteration  16\n",
      "potted plant 64 [(112, 104), (171, 176)]\n",
      "vase 86 [(122, 147), (153, 178)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.05812414]]\n",
      "Iteration  17\n",
      "potted plant 64 [(112, 101), (167, 178)]\n",
      "vase 86 [(118, 147), (149, 178)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.25093942]]\n",
      "Iteration  18\n",
      "vase 86 [(115, 149), (148, 179)]\n",
      "potted plant 64 [(108, 99), (167, 177)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.18639177]]\n",
      "Iteration  19\n",
      "vase 86 [(116, 147), (149, 180)]\n",
      "potted plant 64 [(85, 98), (169, 179)]\n",
      "vase 86 [(96, 150), (113, 177)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.26631556]]\n",
      "Iteration  20\n",
      "vase 86 [(111, 146), (145, 181)]\n",
      "potted plant 64 [(83, 96), (167, 180)]\n",
      "Ref Object: [(83, 96), (167, 96), (167, 180), (83, 180)]\n",
      "Error: [[-24 -20 -12 -20 -12   7 -24   7]] 48.35286961494633\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.21345114]]\n",
      "Unclamped robot Velocities: [[16.13152361]\n",
      " [15.34339634]]\n",
      "Clamped wheel Velocities: [[8.70175594]\n",
      " [7.91362867]] (0.37553213145937425, 0.3901813372280737)\n",
      "Clamped robot Velocities: [[0.27      ]\n",
      " [0.21345114]]\n",
      "Depth: 2.0\n",
      "Iteration  21\n",
      "potted plant 64 [(82, 96), (168, 183)]\n",
      "vase 86 [(110, 145), (144, 182)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.18637519]]\n",
      "Iteration  22\n",
      "potted plant 64 [(79, 94), (165, 182)]\n",
      "vase 86 [(104, 143), (139, 183)]\n",
      "Robot speed limited [[0.27      ]\n",
      " [0.17608089]]\n",
      "Iteration  23\n",
      "potted plant 64 [(66, 92), (160, 182)]\n",
      "potted plant 64 [(103, 93), (160, 182)]\n",
      "vase 86 [(104, 145), (138, 183)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.49669601]]\n",
      "Iteration  24\n",
      "potted plant 64 [(61, 88), (162, 181)]\n",
      "vase 86 [(101, 142), (139, 183)]\n",
      "potted plant 64 [(107, 93), (158, 181)]\n",
      "potted plant 64 [(123, 89), (164, 178)]\n",
      "bottle 44 [(204, 140), (222, 192)]\n",
      "Robot speed limited [[ 0.27      ]\n",
      " [-0.44929674]]\n",
      "Iteration  25\n",
      "potted plant 64 [(46, 85), (156, 185)]\n",
      "vase 86 [(92, 143), (131, 188)]\n",
      "Ref Object: [(46, 85), (156, 85), (156, 185), (46, 185)]\n",
      "Error: [[13 -9 -1 -9 -1  2 13  2]] 22.58317958127243\n",
      "Unclamped robot Velocities: [[5.92562784]\n",
      " [4.93003426]]\n",
      "Clamped wheel Velocities: [[5.92562784]\n",
      " [4.93003426]] (0.3200749861860564, 0.338580443204097)\n",
      "Clamped robot Velocities: [[0.17640451]\n",
      " [0.26963993]]\n",
      "Depth: 2.0\n",
      "Iteration  26\n",
      "potted plant 64 [(18, 77), (147, 188)]\n",
      "Robot speed boosted [[0.14      ]\n",
      " [0.25450453]]\n",
      "Iteration  27\n",
      "potted plant 64 [(16, 72), (145, 187)]\n",
      "vase 86 [(79, 139), (123, 188)]\n",
      "Robot speed boosted [[-0.14     ]\n",
      " [ 0.2143639]]\n",
      "Iteration  28\n",
      "potted plant 64 [(20, 71), (150, 188)]\n",
      "vase 86 [(84, 139), (128, 186)]\n",
      "Robot speed boosted [[-0.14      ]\n",
      " [ 0.20339773]]\n",
      "Iteration  29\n",
      "potted plant 64 [(34, 77), (153, 186)]\n",
      "vase 86 [(93, 141), (132, 188)]\n",
      "Robot speed boosted [[0.14      ]\n",
      " [0.22138662]]\n",
      "Iteration  30\n",
      "potted plant 64 [(48, 74), (163, 189)]\n",
      "vase 86 [(97, 140), (136, 186)]\n",
      "Ref Object: [(48, 74), (163, 74), (163, 189), (48, 189)]\n",
      "Error: [[11  2 -8  2 -8 -2 11 -2]] 19.6468827043885\n",
      "Goal point achieved!!!\n",
      "FPS: 3.4\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "robot_params = {\n",
    "    \"depth\": 2.0,\n",
    "    \"orientation\": 0,\n",
    "    \"wheel_radius\": 0.0325,\n",
    "    \"axle_length\": 0.12\n",
    "}\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": 0.02,\n",
    "    \"Rtime\": 0.1, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 5,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": True,\n",
    "    \"ref_obj\": 64,  # Use potted plant as reference object\n",
    "    \"obj_name\": \"plant\",\n",
    "    \"goal_bbox\": end_bbox_plant,  # This should get the robot to ~(1,2,0) \n",
    "    \"error_window\": 20,\n",
    "    \"speed_lower\": 0.14,  # This ensures motor settings > ~0.3\n",
    "    \"speed_upper\": 0.27  # This ensures motor settings > ~0.5\n",
    "}\n",
    "\n",
    "ibvs_control(robot_params, control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce6ac06a77b4fe393e28bf983eacad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 bed [(33, 69), (114, 69), (114, 124), (33, 124)]\n",
      "chair 62 [(147, 64), (236, 186)]\n",
      "potted plant 64 [(80, 116), (126, 177)]\n",
      "chair 62 [(146, 63), (236, 187)]\n",
      "potted plant 64 [(81, 117), (127, 177)]\n",
      "potted plant 64 [(81, 116), (128, 177)]\n",
      "chair 62 [(145, 64), (236, 187)]\n",
      "chair 62 [(147, 69), (235, 186)]\n",
      "potted plant 64 [(80, 116), (127, 177)]\n",
      "chair 62 [(145, 55), (235, 187)]\n",
      "potted plant 64 [(81, 116), (127, 177)]\n",
      "chair 62 [(145, 57), (236, 187)]\n",
      "potted plant 64 [(81, 117), (127, 177)]\n",
      "chair 62 [(146, 64), (237, 187)]\n",
      "potted plant 64 [(81, 116), (127, 177)]\n",
      "chair 62 [(147, 63), (236, 186)]\n",
      "potted plant 64 [(81, 116), (127, 177)]\n",
      "potted plant 64 [(81, 117), (127, 176)]\n",
      "chair 62 [(149, 71), (235, 185)]\n",
      "chair 62 [(148, 70), (236, 186)]\n",
      "potted plant 64 [(82, 116), (127, 177)]\n",
      "chair 62 [(147, 63), (236, 187)]\n",
      "potted plant 64 [(81, 115), (127, 177)]\n",
      "chair 62 [(148, 64), (235, 185)]\n",
      "potted plant 64 [(80, 114), (127, 177)]\n",
      "chair 62 [(147, 60), (237, 188)]\n",
      "potted plant 64 [(81, 114), (127, 176)]\n",
      "potted plant 64 [(80, 115), (127, 177)]\n",
      "chair 62 [(147, 69), (234, 185)]\n",
      "potted plant 64 [(82, 114), (127, 177)]\n",
      "chair 62 [(144, 62), (235, 185)]\n",
      "chair 62 [(148, 66), (236, 186)]\n",
      "potted plant 64 [(80, 115), (127, 177)]\n",
      "chair 62 [(148, 66), (236, 184)]\n",
      "potted plant 64 [(81, 115), (127, 177)]\n",
      "chair 62 [(147, 62), (236, 185)]\n",
      "potted plant 64 [(81, 115), (127, 177)]\n",
      "vase 86 [(94, 153), (116, 176)]\n",
      "chair 62 [(149, 69), (235, 186)]\n",
      "potted plant 64 [(81, 114), (128, 177)]\n",
      "chair 62 [(147, 60), (236, 186)]\n",
      "potted plant 64 [(81, 116), (127, 177)]\n",
      "FPS: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# Control loop parameters\n",
    "gain = 1.35\n",
    "Rtime = 0.1  # The loop run at 8fps --> 0.125s duration\n",
    "num_iter = 20\n",
    "interval = 2\n",
    "\n",
    "no_motion = False  # Flag to disable motor (for debugging)\n",
    "debug = True\n",
    "\n",
    "# Use TV as reference object \n",
    "ref_obj = 64\n",
    "goal_features = create_feature_pts(mid_bbox_TV)\n",
    "print(ref_obj,COCO_labels[ref_obj], goal_features)\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Run for fixed # of iterations\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    image = undistort(camera.value, mtx, dist) # undistort camera image\n",
    "    detections = model(image) # Use SSD model to detect objects\n",
    "    display_detected(image, detections, width, height, debug=True) # put bounding boxes on detected objects\n",
    "    \n",
    "    # Detect reference object in camera image and place green bounding box around it\n",
    "    obj_features = generate_ref_obj_features(ref_obj, image, detections, width, height)\n",
    "   \n",
    "    image_widget.value = bgr8_to_jpeg(image)  # update image widget with camera image\n",
    "\n",
    "image_widget.value = bgr8_to_jpeg(image)\n",
    "robot.stop()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print (\"FPS: {:.1f}\".format(num_iter/(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe0cdd551294c8fa089cb5330df04ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for  remote ( 74 )\n",
      "remote  identified! Distance from focal center: 19.639619593022797\n",
      "Reference object near focal center !!!\n"
     ]
    }
   ],
   "source": [
    "# Display camera image with bounding boxes for detected objects\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "control_params = {\n",
    "    \"gain\": None,\n",
    "    \"Rtime_course\": 0.04, # The loop run at 8fps --> 0.125s duration\n",
    "    \"Rtime_fine\": 0.02, # The loop run at 8fps --> 0.125s duration\n",
    "    \"num_iter\": 100,\n",
    "    \"interval\": 2,\n",
    "    \"no_motion\": False,  # Flag to disable motor (for debugging)\n",
    "    \"debug\": False,\n",
    "    \"ref_obj\": 74,  # Use horse as reference object\n",
    "    \"obj_name\": \"mouse\",\n",
    "    \"goal_bbox\": None,  # This orients the robot towards a chair, the next ref object\n",
    "    \"error_window\": 50,\n",
    "    \"speed\": 0.31\n",
    "}\n",
    "\n",
    "rotate_n_detect(control_params)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 background\n",
      "2 person\n",
      "3 bicycle\n",
      "4 car\n",
      "5 airplane\n",
      "6 bus\n",
      "7 train\n",
      "8 truck\n",
      "9 boat\n",
      "10 traffic light\n",
      "11 fire hydrant\n",
      "12 12\n",
      "13 stop sign\n",
      "14 parking meter\n",
      "15 bench\n",
      "16 bird\n",
      "17 cat\n",
      "18 dog\n",
      "19 horse\n",
      "20 sheep\n",
      "21 cow\n",
      "22 elephant\n",
      "23 bear\n",
      "24 zebra\n",
      "25 giraffe\n",
      "26 26\n",
      "27 backpack\n",
      "28 umbrella\n",
      "29 29\n",
      "30 30\n",
      "31 handbag\n",
      "32 tie\n",
      "33 suitcase\n",
      "34 frisbee\n",
      "35 skis\n",
      "36 snowboard\n",
      "37 sports ball\n",
      "38 kite\n",
      "39 baseball bat\n",
      "40 baseball glove\n",
      "41 skateboard\n",
      "42 surfboard\n",
      "43 tennis racket\n",
      "44 bottle\n",
      "45 45\n",
      "46 wine glass\n",
      "47 cup\n",
      "48 fork\n",
      "49 knife\n",
      "50 spoon\n",
      "51 bowl\n",
      "52 banana\n",
      "53 apple\n",
      "54 sandwich\n",
      "55 orange\n",
      "56 broccoli\n",
      "57 carrot\n",
      "58 hot dog\n",
      "59 pizza\n",
      "60 donut\n",
      "61 cake\n",
      "62 chair\n",
      "63 couch\n",
      "64 potted plant\n",
      "65 bed\n",
      "66 66\n",
      "67 dining table\n",
      "68 68\n",
      "69 69\n",
      "70 toilet\n",
      "71 71\n",
      "72 tv\n",
      "73 laptop\n",
      "74 mouse\n",
      "75 remote\n",
      "76 keyboard\n",
      "77 cell phone\n",
      "78 microwave\n",
      "79 oven\n",
      "80 toaster\n",
      "81 sink\n",
      "82 refrigerator\n",
      "83 83\n",
      "84 book\n",
      "85 clock\n",
      "86 vase\n",
      "87 scissors\n",
      "88 teddy bear\n",
      "89 hair drier\n",
      "90 toothbrush\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(COCO_labels):\n",
    "    print (i+1, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
